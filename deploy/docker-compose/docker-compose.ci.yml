# CI Docker Compose - Minimal services for integration testing
# Usage: docker compose -f deploy/docker-compose/docker-compose.ci.yml up -d

services:
  # vLLM Semantic Router
  semantic-router:
    build:
      context: ../..
      dockerfile: Dockerfile
    image: ghcr.io/vllm-project/semantic-router:latest
    container_name: semantic-router
    ports:
      - "8801:8801"    # Envoy proxy
      - "8080:8080"    # Health API
      - "19000:19000"  # Envoy admin
    volumes:
      - ../../config:/app/config:ro,z
      - ../../models:/app/models:z
      - ~/.cache/huggingface:/root/.cache/huggingface:z
    environment:
      - CONFIG_FILE=/app/config/config.yaml
      - EXTPROC_HOST=localhost
      - VLLM_BACKEND_HOST=172.28.0.20
      - VLLM_BACKEND_PORT=8002
      - HF_HUB_ENABLE_HF_TRANSFER=1
    networks:
      - semantic-network
    healthcheck:
      test: ["CMD", "curl", "-f", "localhost:8080/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  # LLM Katan - lightweight mock LLM for testing
  llm-katan:
    image: ghcr.io/vllm-project/semantic-router/llm-katan:latest
    container_name: llm-katan
    ports:
      - "8002:8002"
    environment:
      - HF_HUB_ENABLE_HF_TRANSFER=1
    volumes:
      - ../../models:/app/models:z
      - hf-cache:/home/llmkatan/.cache/huggingface
    networks:
      semantic-network:
        ipv4_address: 172.28.0.20
    command: ["llm-katan", "--model", "/app/models/Qwen/Qwen3-0.6B", "--served-model-name", "qwen3", "--host", "0.0.0.0", "--port", "8002"]
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://localhost:8002/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

networks:
  semantic-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.0.0/16

volumes:
  hf-cache:
