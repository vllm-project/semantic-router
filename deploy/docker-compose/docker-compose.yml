services:

  # Semantic Router External Processor Service
  semantic-router:
    build:
      context: ../../
      dockerfile: Dockerfile.extproc
    container_name: semantic-router
    ports:
      - "50051:50051"
    volumes:
      - ../../config:/app/config:ro
      - ../../models:/app/models:ro
      - ~/.cache/huggingface:/root/.cache/huggingface
    environment:
      - LD_LIBRARY_PATH=/app/lib
      - CONFIG_FILE=${CONFIG_FILE:-/app/config/config.yaml}
      - HUGGINGFACE_HUB_CACHE=/root/.cache/huggingface
      - HF_HUB_ENABLE_HF_TRANSFER=1
      - HF_ENDPOINT=https://hf-mirror.com
    networks:
      - semantic-network
    healthcheck:
      test: ["CMD", "curl", "-f", "localhost:8080/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  # Envoy Proxy Service
  envoy:
    image: envoyproxy/envoy:v1.31.7
    container_name: envoy-proxy
    ports:
      - "8801:8801"  # Main proxy port
      - "19000:19000"  # Admin interface
    volumes:
      - ../../config/envoy-docker.yaml:/etc/envoy/envoy.yaml:ro
    command: ["/usr/local/bin/envoy", "-c", "/etc/envoy/envoy.yaml", "--component-log-level", "ext_proc:trace,router:trace,http:trace"]
    depends_on:
      semantic-router:
        condition: service_healthy
    networks:
      - semantic-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:19000/ready"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  # Mock vLLM service for testing profile
  mock-vllm:
    build:
      context: ../../tools/mock-vllm
      dockerfile: Dockerfile
    container_name: mock-vllm
    profiles: ["testing"]
    ports:
      - "8000:8000"
    networks:
      semantic-network:
        ipv4_address: 172.28.0.10
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://localhost:8000/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 5s

  # Prometheus and Grafana for observability
  prometheus:
    image: prom/prometheus:v2.53.0
    container_name: prometheus
    volumes:
      - ../../tools/observability/prometheus.yaml:/etc/prometheus/prometheus.yaml:ro
      - prometheus-data:/prometheus
    command:
      - --config.file=/etc/prometheus/prometheus.yaml
      - --storage.tsdb.retention.time=15d
    environment:
      - ROUTER_TARGET=semantic-router:9190
    ports:
      - "9090:9090"
    networks:
      - semantic-network

  grafana:
    image: grafana/grafana:11.5.1
    container_name: grafana
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - PROMETHEUS_URL=prometheus:9090
      - GF_SECURITY_ALLOW_EMBEDDING=true
      - GF_SECURITY_COOKIE_SAMESITE=lax
      # Configure for subpath serving through dashboard proxy
      - GF_SERVER_ROOT_URL=%(protocol)s://%(domain)s:%(http_port)s/
      - GF_SERVER_SERVE_FROM_SUB_PATH=false
      # Enable anonymous access for iframe embedding
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Viewer
      # Disable login requirement for embedding
      - GF_AUTH_DISABLE_LOGIN_FORM=false
    ports:
      - "3000:3000"
    volumes:
      - ../../tools/observability/grafana-datasource.yaml:/etc/grafana/provisioning/datasources/datasource.yaml:ro
      - ../../tools/observability/grafana-dashboard.yaml:/etc/grafana/provisioning/dashboards/dashboard.yaml:ro
      - ../../tools/observability/llm-router-dashboard.json:/etc/grafana/provisioning/dashboards/llm-router-dashboard.json:ro
      - grafana-data:/var/lib/grafana
    networks:
      - semantic-network
    depends_on:
      - prometheus

  # Open WebUI (optional, used by Dashboard Playground)
  openwebui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: openwebui
    # Expose externally only if you want to access Open WebUI directly
    # ports:
    #   - "3001:8080"
    environment:
      # Add any Open WebUI env here if needed (auth, providers, etc.)
      - WEBUI_NAME=Open WebUI
    volumes:
      - openwebui-data:/app/backend/data
    networks:
      - semantic-network

  # LLM Katan service for testing
  llm-katan:
    build:
      context: ../../e2e-tests/llm-katan
      dockerfile: Dockerfile
    container_name: llm-katan
    profiles: ["testing", "llm-katan"]
    ports:
      - "8002:8000"
    environment:
      - HUGGINGFACE_HUB_TOKEN=${HUGGINGFACE_HUB_TOKEN:-}
    networks:
      - semantic-network
    command: ["llm-katan", "--model", "Qwen/Qwen3-0.6B", "--host", "0.0.0.0", "--port", "8000"]

  # Semantic Router Dashboard
  dashboard:
    build:
      context: ../../
      dockerfile: dashboard/backend/Dockerfile
    image: semantic-router-dashboard:dev
    container_name: semantic-router-dashboard
    command: ["/app/dashboard-backend", "-port=8700", "-static=/app/frontend"]
    environment:
      - DASHBOARD_PORT=8700
      - TARGET_GRAFANA_URL=http://grafana:3000
      - TARGET_PROMETHEUS_URL=http://prometheus:9090
      - TARGET_ROUTER_API_URL=http://semantic-router:8080
      - TARGET_ROUTER_METRICS_URL=http://semantic-router:9190/metrics
      - TARGET_OPENWEBUI_URL=http://openwebui:8080
    ports:
      - "8700:8700"
    networks:
      - semantic-network
    depends_on:
      semantic-router:
        condition: service_healthy
      grafana:
        condition: service_started
      prometheus:
        condition: service_started
      openwebui:
        condition: service_started
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8700/healthz"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s

networks:
  semantic-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.0.0/16

volumes:
  models-cache:
    driver: local
  prometheus-data:
  grafana-data:
  openwebui-data:
