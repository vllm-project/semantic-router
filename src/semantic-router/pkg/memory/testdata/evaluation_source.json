{
  "description": "Auto-generated from 217 Go source files under pkg/. 117 chunks sampled across 40 packages.",
  "config": {
    "k": 5,
    "threshold": 0.3,
    "alphas": [
      1,
      0.7,
      0.5,
      0.3
    ],
    "max_depth": 3,
    "score_prop_alpha": 0.6
  },
  "entries": [
    {
      "id": "anthropic/client-0",
      "cluster": "anthropic",
      "content": "// Package anthropic provides transformation functions between OpenAI and Anthropic API formats.\n// Used for Envoy-routed requests where the router transforms request/response bodies.\npackage anthropic\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/anthropics/anthropic-sdk-go\"\n\t\"github.com/openai/openai-go\"\n\n\t\"github.com/vllm-project/semantic-router/src/semantic-router/pkg/observability/logging\"\n)"
    },
    {
      "id": "anthropic/client-4",
      "cluster": "anthropic",
      "content": "var messages []anthropic.MessageParam\n\tvar systemPrompt string\n\n\t// Process messages - extract system prompt separately (Anthropic requirement)\n\tfor _, msg := range openAIRequest.Messages {\n\t\tswitch {\n\t\tcase msg.OfSystem != nil:\n\t\t\tsystemPrompt = extractSystemContent(msg.OfSystem)\n\t\tcase msg.OfUser != nil:\n\t\t\tcontent := extractUserContent(msg.OfUser)\n\t\t\tmessages = append(messages, anthropic.NewUserMessage(anthropic.NewTextBlock(content)))\n\t\tcase msg.OfAssistant != nil:\n\t\t\tcontent := extractAssistantContent(msg.OfAssistant)\n\t\t\tmessages = append(messages, anthropic.NewAssistantMessage(anthropic.NewTextBlock(content)))\n\t\t}"
    },
    {
      "id": "anthropic/client-8",
      "cluster": "anthropic",
      "content": "var resp anthropic.Message\n\tif err := json.Unmarshal(anthropicResponse, \u0026resp); err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to parse Anthropic response: %w\", err)\n\t}\n\n\tlogging.Debugf(\"Parsed Anthropic response - ID: %s, Content blocks: %d, StopReason: %s\", resp.ID, len(resp.Content), resp.StopReason)\n\n\t// Extract text content\n\tvar content string\n\tfor _, block := range resp.Content {\n\t\tif block.Type == \"text\" {\n\t\t\tcontent += block.Text\n\t\t}"
    },
    {
      "id": "apis/vllm.ai/v1alpha1/doc-0",
      "cluster": "apis/vllm.ai/v1alpha1",
      "content": "// Package v1alpha1 contains API Schema definitions for the v1alpha1 API group\n// +kubebuilder:object:generate=true\n// +groupName=vllm.ai\npackage v1alpha1"
    },
    {
      "id": "apis/vllm.ai/v1alpha1/types_route-10",
      "cluster": "apis/vllm.ai/v1alpha1",
      "content": "// KeywordSignal defines a keyword-based signal extraction rule\ntype KeywordSignal struct {\n\t// Name is the unique identifier for this rule (also used as category name)\n\t// +kubebuilder:validation:Required\n\t// +kubebuilder:validation:MinLength=1\n\t// +kubebuilder:validation:MaxLength=100\n\tName string `json:\"name\" yaml:\"name\"`\n\n\t// Operator defines the logical operator for keywords (AND/OR)\n\t// +kubebuilder:validation:Required"
    },
    {
      "id": "apis/vllm.ai/v1alpha1/zz_generated.deepcopy-5",
      "cluster": "apis/vllm.ai/v1alpha1",
      "content": "func (in *DomainSignal) DeepCopy() *DomainSignal {\n\tif in == nil {\n\t\treturn nil\n\t}\n\tout := new(DomainSignal)\n\tin.DeepCopyInto(out)\n\treturn out\n}\n\n// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.\nfunc (in *EmbeddingSignal) DeepCopyInto(out *EmbeddingSignal) {\n\t*out = *in\n\tif in.Candidates != nil {\n\t\tin, out := \u0026in.Candidates, \u0026out.Candidates\n\t\t*out = make([]string, len(*in))\n\t\tcopy(*out, *in)\n\t}"
    },
    {
      "id": "apiserver/config-0",
      "cluster": "apiserver",
      "content": "//go:build !windows \u0026\u0026 cgo\n\npackage apiserver\n\nimport (\n\t\"github.com/vllm-project/semantic-router/src/semantic-router/pkg/config\"\n\t\"github.com/vllm-project/semantic-router/src/semantic-router/pkg/memory\"\n\t\"github.com/vllm-project/semantic-router/src/semantic-router/pkg/services\"\n)\n\n// ClassificationAPIServer holds the server state and dependencies\ntype ClassificationAPIServer struct {\n\tclassificationSvc     *services.ClassificationService\n\tconfig                *config.RouterConfig\n\tmemoryStore           memory.Store\n\tenableSystemPromptAPI bool\n}"
    },
    {
      "id": "apiserver/route_embeddings-11",
      "cluster": "apiserver",
      "content": "func (s *ClassificationAPIServer) handleBatchSimilarity(w http.ResponseWriter, r *http.Request) {\n\t// Parse request\n\tvar req BatchSimilarityRequest\n\tif err := s.parseJSONRequest(r, \u0026req); err != nil {\n\t\ts.writeErrorResponse(w, http.StatusBadRequest, \"INVALID_INPUT\", err.Error())\n\t\treturn\n\t}\n\n\t// Validate input\n\tif req.Query == \"\" {\n\t\ts.writeErrorResponse(w, http.StatusBadRequest, \"INVALID_INPUT\", \"query must be provided\")\n\t\treturn\n\t}"
    },
    {
      "id": "apiserver/route_model_info-10",
      "cluster": "apiserver",
      "content": "}\n\n// getEmbeddingModelsInfo returns information about loaded embedding models\nfunc (s *ClassificationAPIServer) getEmbeddingModelsInfo() []ModelInfo {\n\tvar models []ModelInfo\n\n\t// Query embedding models info from Rust FFI\n\tembeddingInfo, err := candle_binding.GetEmbeddingModelsInfo()\n\tif err != nil {\n\t\tlogging.Warnf(\"Failed to get embedding models info: %v\", err)\n\t\treturn models\n\t}\n\n\t// Convert to ModelInfo format"
    },
    {
      "id": "authz/chain-0",
      "cluster": "authz",
      "content": "package authz\n\nimport (\n\t\"fmt\"\n\t\"strings\"\n\n\t\"github.com/vllm-project/semantic-router/src/semantic-router/pkg/observability/logging\"\n)\n\n// CredentialResolver chains multiple Providers and resolves credentials\n// using first-match semantics: the first provider that returns a non-empty key wins.\n//\n// Typical chain order:\n//  1. HeaderInjectionProvider (keys from ext_authz / Authorino / Envoy Gateway)"
    },
    {
      "id": "authz/chain-8",
      "cluster": "authz",
      "content": "// HeadersToStrip returns the union of all headers that providers want stripped\n// before forwarding upstream. Deduplicated.\nfunc (r *CredentialResolver) HeadersToStrip() []string {\n\tif r == nil {\n\t\treturn nil\n\t}\n\tseen := make(map[string]bool)\n\tvar result []string\n\tfor _, p := range r.providers {\n\t\tfor _, h := range p.HeadersToStrip() {\n\t\t\tif !seen[h] {\n\t\t\t\tseen[h] = true\n\t\t\t\tresult = append(result, h)\n\t\t\t}"
    },
    {
      "id": "authz/provider-0",
      "cluster": "authz",
      "content": "// Package authz provides a pluggable credential resolution framework for\n// external authorization in the semantic router.\n//\n// The router needs to obtain per-user API keys for upstream LLM providers\n// (OpenAI, Anthropic, Gemini, etc.). These keys can come from multiple sources:\n//\n//   - Header injection: An ext_authz service (Authorino, custom, or Envoy Gateway\n//     SecurityPolicy) validates the user's Bearer token and injects per-user"
    },
    {
      "id": "cache/benchmark-0",
      "cluster": "cache",
      "content": "//go:build !windows \u0026\u0026 cgo\n\npackage cache\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"math\"\n\t\"math/rand\"\n\t\"os\"\n\t\"sort\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"time\"\n\n\tcandle_binding \"github.com/vllm-project/semantic-router/candle-binding\"\n)\n\n// BenchmarkConfig defines the parameters for a benchmark run\ntype BenchmarkConfig struct {\n\tCacheSize         int     // Number of entries to pre-populate\n\tConcurrencyLevels []int   // Different concurrency levels to test\n\tRequestsPerLevel  int     // Number of requests per concurrency level\n\tSimilarityThresh  float32 // Similarity threshold\n\tUseHNSW           bool    // Whether to use HNSW indexing\n\tEmbeddingModel    string  // \"bert\", \"qwen3\", or \"gemma\"\n\tHitRatio          float64 // Expected cache hit ratio (0.0-1.0)\n}"
    },
    {
      "id": "cache/hybrid_cache-40",
      "cluster": "cache",
      "content": "return nil, false, nil\n}\n\n// FindSimilarWithThreshold searches for semantically similar cached requests using a specific threshold\nfunc (h *HybridCache) FindSimilarWithThreshold(model string, query string, threshold float32) ([]byte, bool, error) {\n\tstart := time.Now()\n\n\tif !h.enabled {\n\t\treturn nil, false, nil\n\t}\n\n\tqueryPreview := query\n\tif len(query) \u003e 50 {\n\t\tqueryPreview = query[:50] + \"...\"\n\t}"
    },
    {
      "id": "cache/inmemory_cache_stub-3",
      "cluster": "cache",
      "content": "func (c *InMemoryCache) FindSimilar(model string, query string) ([]byte, bool, error) {\n\tif !c.enabled {\n\t\treturn nil, false, nil\n\t}\n\t// Always return miss for mock unless we want to simulate hits\n\treturn nil, false, nil\n}\n\n// FindSimilarWithThreshold searches for semantically similar cached requests using a specific threshold\nfunc (c *InMemoryCache) FindSimilarWithThreshold(model string, query string, threshold float32) ([]byte, bool, error) {"
    },
    {
      "id": "classification/authz_classifier-0",
      "cluster": "classification",
      "content": "package classification\n\nimport (\n\t\"fmt\"\n\t\"strings\"\n\n\t\"github.com/vllm-project/semantic-router/src/semantic-router/pkg/config\"\n\t\"github.com/vllm-project/semantic-router/src/semantic-router/pkg/observability/logging\"\n)\n\n// AuthzResult represents the result of authz signal classification.\n// It contains only the matched role names â€” the decision engine uses these\n// to select models via modelRefs."
    },
    {
      "id": "classification/classifier-176",
      "cluster": "classification",
      "content": "func (c *Classifier) AnalyzeContentForPIIWithThreshold(contentList []string, threshold float32) (bool, []PIIAnalysisResult, error) {\n\tif !c.IsPIIEnabled() {\n\t\treturn false, nil, fmt.Errorf(\"PII detection is not properly configured\")\n\t}\n\n\tvar analysisResults []PIIAnalysisResult\n\thasPII := false\n\n\tfor i, content := range contentList {\n\t\tif content == \"\" {\n\t\t\tcontinue\n\t\t}\n\n\t\tvar result PIIAnalysisResult\n\t\tresult.Content = content\n\t\tresult.ContentIndex = i"
    },
    {
      "id": "classification/language_classifier-0",
      "cluster": "classification",
      "content": "package classification\n\nimport (\n\t\"github.com/abadojack/whatlanggo\"\n\n\t\"github.com/vllm-project/semantic-router/src/semantic-router/pkg/config\"\n\t\"github.com/vllm-project/semantic-router/src/semantic-router/pkg/observability/logging\"\n)\n\n// LanguageClassifier implements language detection using whatlanggo library\n// Supports 100+ languages with high accuracy\ntype LanguageClassifier struct {\n\trules []config.LanguageRule\n}"
    },
    {
      "id": "config/config-0",
      "cluster": "config",
      "content": "package config\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"strconv\"\n\t\"strings\"\n\n\t\"github.com/vllm-project/semantic-router/src/semantic-router/pkg/observability/logging\"\n)\n\n// ConfigSource defines where to load dynamic configuration from\ntype ConfigSource string\n\nconst (\n\t// ConfigSourceFile loads configuration from file (default)\n\tConfigSourceFile ConfigSource = \"file\"\n\t// ConfigSourceKubernetes loads configuration from Kubernetes CRDs"
    },
    {
      "id": "config/config-160",
      "cluster": "config",
      "content": "AllowByDefault bool `yaml:\"allow_by_default\"`\n\n\t// List of specific PII types to allow when AllowByDefault is false\n\t// This field explicitly lists the PII types that are allowed for this model\n\tPIITypes []string `yaml:\"pii_types_allowed,omitempty\"`\n}\n\n// PIIType constants for common PII types (matching pii_type_mapping.json)\nconst (\n\tPIITypeAge             = \"AGE\"               // Age information\n\tPIITypeCreditCard      = \"CREDIT_CARD\"       // Credit Card Number\n\tPIITypeDateTime        = \"DATE_TIME\"         // Date/Time information\n\tPIITypeDomainName      = \"DOMAIN_NAME\"       // Domain/Website names\n\tPIITypeEmailAddress    = \"EMAIL_ADDRESS\"     // Email Address\n\tPIITypeGPE             = \"GPE\"               // Geopolitical Entity\n\tPIITypeIBANCode        = \"IBAN_CODE\"         // International Bank Account Number\n\tPIITypeIPAddress       = \"IP_ADDRESS\"        // IP Address\n\tPIITypeNoPII           = \"NO_PII\"            // No PII detected\n\tPIITypeNRP             = \"NRP\"               // Nationality/Religious/Political group\n\tPIITypeOrganization    = \"ORGANIZATION\"      // Organization names\n\tPIITypePerson          = \"PERSON\"            // Person names\n\tPIITypePhoneNumber     = \"PHONE_NUMBER\"      // Phone Number\n\tPIITypeStreetAddress   = \"STREET_ADDRESS\"    // Physical Address\n\tPIITypeUSDriverLicense = \"US_DRIVER_LICENSE\" // US Driver's License Number\n\tPIITypeUSSSN           = \"US_SSN\"            // US Social Security Number\n\tPIITypeZipCode         = \"ZIP_CODE\"          // ZIP/Postal codes\n)"
    },
    {
      "id": "config/helper-63",
      "cluster": "config",
      "content": "//  2. base_url path + type-default suffix from providerTypeRegistry.\n//  3. Type-default suffix alone if base_url has no path component.\n//\n// Returns error if the type is not recognised or base_url is unparsable.\nfunc (p *ProviderProfile) ResolveChatPath() (string, error) {\n\tif p == nil {\n\t\treturn \"\", fmt.Errorf(\"provider profile is nil\")\n\t}\n\n\tinfo, ok := providerTypeRegistry[p.Type]\n\tif !ok {\n\t\treturn \"\", fmt.Errorf(\"unknown provider type %q â€” cannot determine chat path\", p.Type)\n\t}"
    },
    {
      "id": "consts/consts-0",
      "cluster": "consts",
      "content": "package consts\n\n// UnknownLabel is a canonical fallback label value used across the codebase\n// when a more specific value (e.g., model, category, reason) is not available.\nconst UnknownLabel = \"unknown\""
    },
    {
      "id": "decision/engine-0",
      "cluster": "decision",
      "content": "/*\nCopyright 2025 vLLM Semantic Router.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/"
    },
    {
      "id": "decision/engine-6",
      "cluster": "decision",
      "content": "return e.EvaluateDecisionsWithSignals(\u0026SignalMatches{\n\t\tKeywordRules:   matchedKeywordRules,\n\t\tEmbeddingRules: matchedEmbeddingRules,\n\t\tDomainRules:    matchedDomainRules,\n\t\tFactCheckRules: nil,\n\t})\n}\n\n// EvaluateDecisionsWithSignals evaluates all decisions using SignalMatches\n// This is the new method that supports all signal types including fact_check\nfunc (e *DecisionEngine) EvaluateDecisionsWithSignals(signals *SignalMatches) (*DecisionResult, error) {"
    },
    {
      "id": "decision/engine-12",
      "cluster": "decision",
      "content": "if !matched {\n\t\treturn false, 0, nil\n\t}\n\n\t// Use real confidence score if available (e.g., embedding similarity = 0.88),\n\t// otherwise fall back to 1.0 for backward compatibility.\n\tsignalKey := fmt.Sprintf(\"%s:%s\", normalizedType, name)\n\tif signals.SignalConfidences != nil {\n\t\tif score, ok := signals.SignalConfidences[signalKey]; ok \u0026\u0026 score \u003e 0 {\n\t\t\tconfidence = score\n\t\t} else {\n\t\t\tconfidence = 1.0\n\t\t}"
    },
    {
      "id": "extproc/memory_helpers-0",
      "cluster": "extproc",
      "content": "package extproc\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"strings\"\n\n\t\"github.com/vllm-project/semantic-router/src/semantic-router/pkg/memory\"\n\t\"github.com/vllm-project/semantic-router/src/semantic-router/pkg/observability/logging\"\n\t\"github.com/vllm-project/semantic-router/src/semantic-router/pkg/responseapi\"\n)\n\n// extractAutoStore checks if auto_store is enabled.\n// Priority: per-decision plugin config \u003e request-level memory_config.auto_store."
    },
    {
      "id": "extproc/req_filter_classification-33",
      "cluster": "extproc",
      "content": "// This implements \"automatic scoring by signals\" - when the FeedbackDetector classifies user\n// follow-up messages as \"satisfied\" or \"wrong_answer\", we automatically update Elo ratings.\n//\n// Signal mapping:\n// - \"satisfied\" â†’ Model performed well, record as implicit win\n// - \"wrong_answer\" â†’ Model performed poorly, record as implicit loss\n// - \"need_clarification\" / \"want_different\" â†’ Neutral, no Elo update"
    },
    {
      "id": "extproc/req_filter_rag_hybrid-13",
      "cluster": "extproc",
      "content": "logging.Infof(\"Hybrid RAG: primary backend (%s) succeeded\", hybridConfig.Primary)\n\t\treturn primaryContext, nil\n\t}\n\n\tif fallbackErr == nil \u0026\u0026 fallbackContext != \"\" {\n\t\tlogging.Infof(\"Hybrid RAG: fallback backend (%s) succeeded\", hybridConfig.Fallback)\n\t\treturn fallbackContext, nil\n\t}\n\n\treturn \"\", fmt.Errorf(\"both backends failed: primary=%w, fallback=%w\", primaryErr, fallbackErr)\n}\n\n// retrieveFromBackend is a helper to retrieve from a specific backend"
    },
    {
      "id": "headers/headers-0",
      "cluster": "headers",
      "content": "package headers\n\n// Package headers provides constants for all custom HTTP headers used in the semantic router.\n// All custom headers follow the \"x-\" prefix convention for non-standard HTTP headers.\n\n// Request Headers\n// These headers are used in incoming requests to the semantic router.\nconst (\n\t// RequestID is the unique identifier for tracking a request through the system.\n\t// This header is case-insensitive when read from incoming requests."
    },
    {
      "id": "headers/headers-8",
      "cluster": "headers",
      "content": "// VSRMatchedEmbeddings contains comma-separated list of matched embedding rule names.\n\t// Example: \"code_debug,technical_help\"\n\tVSRMatchedEmbeddings = \"x-vsr-matched-embeddings\"\n\n\t// VSRMatchedDomains contains comma-separated list of matched domain rule names.\n\t// Example: \"computer_science,mathematics\"\n\tVSRMatchedDomains = \"x-vsr-matched-domains\"\n\n\t// VSRMatchedFactCheck contains the fact-check signal result."
    },
    {
      "id": "headers/headers-16",
      "cluster": "headers",
      "content": "FactCheckNeeded = \"x-vsr-fact-check-needed\"\n\n\t// UnverifiedFactualResponse indicates the response contains factual claims that could not be verified.\n\t// This occurs when the prompt was classified as needing fact-checking but no tool/RAG context\n\t// was available to verify the response against.\n\t// Value: \"true\"\n\tUnverifiedFactualResponse = \"x-vsr-unverified-factual-response\"\n\n\t// VerificationContextMissing indicates that no tool/RAG context was available for verification."
    },
    {
      "id": "hnsw/hnsw-0",
      "cluster": "hnsw",
      "content": "//go:build !windows \u0026\u0026 cgo\n\n// Package hnsw provides a Hierarchical Navigable Small World (HNSW) graph implementation\n// for fast approximate nearest neighbor search on high-dimensional vectors.\n//\n// HNSW enables O(log n) similarity search compared to O(n) brute-force search,\n// making it ideal for large-scale embedding similarity matching.\n//\n// Key features:\n//   - O(log n) search complexity\n//   - Configurable accuracy vs speed tradeoff via M and ef parameters"
    },
    {
      "id": "hnsw/hnsw-11",
      "cluster": "hnsw",
      "content": "sortBySimDesc(results)\n\tif len(results) \u003e k {\n\t\tresults = results[:k]\n\t}\n\n\treturn results\n}\n\n// Size returns the number of nodes in the index\nfunc (h *Index) Size() int {\n\th.mu.RLock()\n\tdefer h.mu.RUnlock()\n\treturn len(h.nodes)\n}\n\n// GetEmbedding returns the embedding for a given node ID\nfunc (h *Index) GetEmbedding(id int) ([]float32, bool) {\n\th.mu.RLock()\n\tdefer h.mu.RUnlock()\n\n\tif node, ok := h.nodes[id]; ok {\n\t\treturn node.Embedding, true\n\t}"
    },
    {
      "id": "hnsw/hnsw-22",
      "cluster": "hnsw",
      "content": "return result\n}\n\n// distance calculates cosine distance (lower is more similar)\n// Uses negative dot product since embeddings are normalized\nfunc (h *Index) distance(a, b []float32) float32 {\n\tdotProduct := dotProductSIMD(a, b)\n\treturn -dotProduct // Negate so higher similarity = lower distance\n}\n\n// sortBySimDesc sorts SearchResults by similarity in descending order\nfunc sortBySimDesc(results []SearchResult) {"
    },
    {
      "id": "imagegen/backend_openai-0",
      "cluster": "imagegen",
      "content": "package imagegen\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n\t\"net/http\"\n\t\"time\"\n\n\t\"github.com/vllm-project/semantic-router/src/semantic-router/pkg/config\"\n)\n\n// OpenAIBackend implements the Backend interface for OpenAI image generation\ntype OpenAIBackend struct {\n\tbaseURL    string\n\tapiKey     string\n\tmodel      string\n\tquality    string\n\tstyle      string\n\thttpClient *http.Client\n}"
    },
    {
      "id": "imagegen/backend_openai-10",
      "cluster": "imagegen",
      "content": "type openAIImageResponse struct {\n\tCreated int64             `json:\"created\"`\n\tData    []openAIImageData `json:\"data\"`\n}\n\ntype openAIImageData struct {\n\tURL           string `json:\"url,omitempty\"`\n\tB64JSON       string `json:\"b64_json,omitempty\"`\n\tRevisedPrompt string `json:\"revised_prompt,omitempty\"`\n}"
    },
    {
      "id": "imagegen/backend_vllm_omni-9",
      "cluster": "imagegen",
      "content": "type vllmOmniExtraBody struct {\n\tWidth             int     `json:\"width,omitempty\"`\n\tHeight            int     `json:\"height,omitempty\"`\n\tNumInferenceSteps int     `json:\"num_inference_steps,omitempty\"`\n\tTrueCFGScale      float64 `json:\"true_cfg_scale,omitempty\"`\n\tSeed              *int    `json:\"seed,omitempty\"`\n\tNegativePrompt    string  `json:\"negative_prompt,omitempty\"`\n}\n\ntype vllmOmniResponse struct {\n\tID      string           `json:\"id\"`\n\tObject  string           `json:\"object\"`\n\tCreated int64            `json:\"created\"`\n\tModel   string           `json:\"model\"`\n\tChoices []vllmOmniChoice `json:\"choices\"`\n}"
    },
    {
      "id": "k8s/controller-0",
      "cluster": "k8s",
      "content": "/*\nCopyright 2025 vLLM Semantic Router.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/"
    },
    {
      "id": "k8s/converter-13",
      "cluster": "k8s",
      "content": "func validatePluginConfiguration(pluginType string, rawConfig []byte) error {\n\tif len(rawConfig) == 0 {\n\t\treturn nil // Empty configuration is allowed\n\t}\n\n\tswitch pluginType {\n\tcase \"semantic-cache\":\n\t\tvar cfg config.SemanticCachePluginConfig\n\t\tdecoder := json.NewDecoder(bytes.NewReader(rawConfig))\n\t\tdecoder.DisallowUnknownFields()\n\t\tif err := decoder.Decode(\u0026cfg); err != nil {\n\t\t\treturn fmt.Errorf(\"failed to unmarshal semantic-cache config: %w\", err)\n\t\t}"
    },
    {
      "id": "k8s/reconciler-12",
      "cluster": "k8s",
      "content": "func (r *Reconciler) getIntelligentPool(ctx context.Context) (*v1alpha1.IntelligentPool, error) {\n\tpoolList := \u0026v1alpha1.IntelligentPoolList{}\n\tif err := r.client.List(ctx, poolList, client.InNamespace(r.namespace)); err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to list IntelligentPools: %w\", err)\n\t}\n\n\tif len(poolList.Items) == 0 {\n\t\treturn nil, fmt.Errorf(\"no IntelligentPool found in namespace %s\", r.namespace)\n\t}"
    },
    {
      "id": "latency/cache-0",
      "cluster": "latency",
      "content": "package latency\n\nimport (\n\t\"sort\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/vllm-project/semantic-router/src/semantic-router/pkg/observability/logging\"\n)\n\n// TPOTAlpha is the exponential moving average weight for TPOT smoothing\n// 0.3 means: 30% new value, 70% historical average\nconst TPOTAlpha = 0.3\n\n// MaxTPOTHistorySize limits the number of recent TPOT values stored per model\n// This prevents unbounded memory growth while providing enough data for percentile calculation"
    },
    {
      "id": "latency/cache-9",
      "cluster": "latency",
      "content": "// Returns the TPOT value at the specified percentile and whether data exists\n// Works with any number of observations (1+): uses average for 1-2, percentile for 3+\nfunc GetTPOTPercentile(model string, percentile int) (float64, bool) {\n\t// Normalize model name\n\tmodel = strings.TrimSpace(model)\n\tif model == \"\" || percentile \u003c 1 || percentile \u003e 100 {\n\t\treturn 0, false\n\t}\n\n\tglobalTPOTCache.mu.RLock()\n\tstats, exists := globalTPOTCache.cache[model]\n\tif !exists || len(stats.RecentTPOTs) == 0 {\n\t\tglobalTPOTCache.mu.RUnlock()\n\t\treturn 0, false\n\t}"
    },
    {
      "id": "latency/cache-18",
      "cluster": "latency",
      "content": "const minTTFT = 0.0001 // 0.1ms - very fast but realistic lower bound\n\tconst maxTTFT = 1000.0 // 1000s - very slow but possible upper bound\n\tif model == \"\" {\n\t\tlogging.Debugf(\"UpdateTTFT: skipping invalid input (empty model name)\")\n\t\treturn\n\t}\n\tif ttft \u003c= 0 {\n\t\tlogging.Debugf(\"UpdateTTFT: skipping invalid input (model=%q, ttft=%.4f - must be positive)\", model, ttft)\n\t\treturn\n\t}\n\tif ttft \u003c minTTFT || ttft \u003e maxTTFT {\n\t\tlogging.Warnf(\"UpdateTTFT: suspicious TTFT value (model=%q, ttft=%.4f - outside normal range [%.4f, %.4f])\", model, ttft, minTTFT, maxTTFT)\n\t\t// Still record it, but log a warning"
    },
    {
      "id": "logo/logo-0",
      "cluster": "logo",
      "content": "package logo\n\nimport (\n\t\"fmt\"\n)\n\n// ANSI color codes\nconst (\n\tcolorReset  = \"\\033[0m\"\n\tcolorOrange = \"\\033[38;2;254;181;22m\" // #FEB516 - vLLM V left side\n\tcolorBlue   = \"\\033[38;2;48;162;255m\" // #30A2FF - vLLM V right side\n\tcolorWhite  = \"\\033[97m\"              // White - for LLM and SR\n)\n\n// PrintVLLMLogo prints the vLLM SR logo with colors\nfunc PrintVLLMLogo() {\n\t// Logo design: vLLM SR\n\t// v = left side orange, right side blue"
    },
    {
      "id": "logo/logo-1",
      "cluster": "logo",
      "content": "// LLM SR = white\n\tlogo := []string{\n\t\t\"\",\n\t\tcolorOrange + `##` + colorWhite + `          ` + colorBlue + `##` + colorWhite + `  ##        ##        ##      ##    ######    ########` + colorReset,\n\t\tcolorOrange + ` ##` + colorWhite + `        ` + colorBlue + `##` + colorWhite + `   ##        ##        ###    ###   ##    ##   ##    ##` + colorReset,\n\t\tcolorOrange + `  ##` + colorWhite + `      ` + colorBlue + `##` + colorWhite + `    ##        ##        ####  ####   ##         ##    ##` + colorReset,\n\t\tcolorOrange + `   ##` + colorWhite + `    ` + colorBlue + `##` + colorWhite + `     ##        ##        ## #### ##    ####     ########` + colorReset,\n\t\tcolorOrange + `    ##` + colorWhite + `  ` + colorBlue + `##` + colorWhite + `      ##        ##        ##  ##  ##       ##    ##  ##` + colorReset,\n\t\tcolorOrange + `     ##` + colorBlue + `##` + colorWhite + `       ##        ##        ##      ##   ##    ##   ##   ##` + colorReset,\n\t\tcolorOrange + `      ` + colorBlue + `##` + colorWhite + `        ########  ########  ##      ##    ######    ##    ##` + colorReset,\n\t\t\"\",\n\t}\nfor _, line := range logo {\n\t\tfmt.Println(line)\n\t}\n}"
    },
    {
      "id": "looper/base-0",
      "cluster": "looper",
      "content": "/*\nCopyright 2025 vLLM Semantic Router.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/"
    },
    {
      "id": "looper/confidence-16",
      "cluster": "looper",
      "content": "cost := params.Pricing.PromptPer1M\n\t\t\t\tif cost \u003e 0 \u0026\u0026 costRange \u003e 0 {\n\t\t\t\t\tcostScore = 1.0 - (cost-minCost)/costRange\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// POMDP-inspired value function:\n\t\t// value = (1 - tradeoff) * quality + tradeoff * costScore\n\t\t// When tradeoff = 0: pure quality ordering\n\t\t// When tradeoff = 1: pure cost ordering (cheapest first)\n\t\t// When tradeoff = 0.3: favor quality but consider cost\n\t\tvalue := (1-tradeoff)*quality + tradeoff*costScore\n\t\treturn value\n\t}"
    },
    {
      "id": "looper/remom-3",
      "cluster": "looper",
      "content": "type ModelCall struct {\n\tModel    string\n\tLoRAName string\n}\n\n// ReferenceResponse represents a response used as reference in synthesis\ntype ReferenceResponse struct {\n\tContent   string\n\tReasoning string\n\tModel     string\n}\n\n// SynthesisData contains data for template rendering\ntype SynthesisData struct {\n\tOriginalContent    string\n\tReferenceResponses []ReferenceResponse\n}\n\n// RoundResponse represents responses from a single round (for visualization)"
    },
    {
      "id": "mcp/factory-0",
      "cluster": "mcp",
      "content": "package mcp\n\nimport (\n\t\"fmt\"\n\t\"log\"\n)\n\n// ClientFactory creates MCP clients based on configuration\ntype ClientFactory struct{}\n\n// NewClientFactory creates a new client factory\nfunc NewClientFactory() *ClientFactory {\n\treturn \u0026ClientFactory{}\n}\n\n// CreateClient creates an MCP client based on the configuration\nfunc (f *ClientFactory) CreateClient(name string, config ClientConfig) (MCPClient, error) {"
    },
    {
      "id": "mcp/http_client-22",
      "cluster": "mcp",
      "content": "// Make the request\n\tresp, err := c.httpClient.Do(req)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"HTTP request failed: %w\", err)\n\t}\n\tdefer resp.Body.Close()\n\n\t// Read response body\n\tresponseBody, err := io.ReadAll(resp.Body)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to read response body: %w\", err)\n\t}\n\n\t// Check status code\n\tif resp.StatusCode \u003c 200 || resp.StatusCode \u003e= 300 {\n\t\treturn nil, fmt.Errorf(\"HTTP request failed with status %d: %s\", resp.StatusCode, string(responseBody))\n\t}"
    },
    {
      "id": "mcp/types-2",
      "cluster": "mcp",
      "content": "// ServerInfo represents MCP server information\ntype ServerInfo struct {\n\tName         string             `json:\"name\"`\n\tVersion      string             `json:\"version\"`\n\tProtocol     ProtocolVersion    `json:\"protocolVersion\"`\n\tCapabilities ServerCapabilities `json:\"capabilities\"`\n\tInstructions string             `json:\"instructions,omitempty\"`\n}\n\n// ProtocolVersion represents the MCP protocol version"
    },
    {
      "id": "mcp/api/types-0",
      "cluster": "mcp/api",
      "content": "// Package api defines the MCP protocol contract for semantic router classification.\n//\n// This package provides strongly-typed definitions for the JSON messages exchanged between\n// the Go client and MCP classification servers. These types ensure consistency and can be\n// used by both client and server implementations.\n//\n// Protocol Version: 1.0\n//\n// For Python MCP servers, use these JSON formats when implementing classification tools."
    },
    {
      "id": "mcp/api/types-3",
      "cluster": "mcp/api",
      "content": "Class int `json:\"class\"`\n\n\t// Confidence is the prediction confidence, ranging from 0.0 to 1.0\n\tConfidence float32 `json:\"confidence\"`\n\n\t// Model is the recommended model for routing this request (optional).\n\t// If provided, the router will use this model instead of the default_model.\n\t// Example: \"openai/gpt-oss-20b\", \"anthropic/claude-3-opus\"\n\tModel string `json:\"model,omitempty\"`\n\n\t// UseReasoning indicates whether to enable reasoning mode for this request (optional)."
    },
    {
      "id": "mcp/api/types-6",
      "cluster": "mcp/api",
      "content": "Class int `json:\"class\"`\n\n\t// Confidence is the prediction confidence, ranging from 0.0 to 1.0\n\tConfidence float32 `json:\"confidence\"`\n\n\t// Probabilities is the full probability distribution across all categories.\n\t// The array length must match the number of categories, and values should sum to ~1.0.\n\tProbabilities []float32 `json:\"probabilities\"`\n\n\t// Model is the recommended model for routing this request (optional)"
    },
    {
      "id": "memory/categorizer-0",
      "cluster": "memory",
      "content": "package memory\n\nimport (\n\t\"context\"\n\t\"crypto/sha256\"\n\t\"fmt\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/vllm-project/semantic-router/src/semantic-router/pkg/observability/logging\"\n)\n\n// CategorizerConfig holds tunable parameters for auto-categorization and summary generation.\ntype CategorizerConfig struct {\n\t// AbstractMaxLen is the max character length for L0 abstracts.\n\tAbstractMaxLen int\n\n\t// OverviewMaxLen is the max character length for L1 overviews."
    },
    {
      "id": "memory/inmemory_hierarchical-4",
      "cluster": "memory",
      "content": "s.mu.RLock()\n\tdefer s.mu.RUnlock()\n\n\tqueryEmbedding, err := GenerateEmbedding(opts.Query, s.embeddingConfig)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tlimit := opts.Limit\n\tif limit \u003c= 0 {\n\t\tlimit = DefaultHierarchicalLimit\n\t}\n\tthreshold := opts.Threshold\n\tif threshold \u003c= 0 {\n\t\tthreshold = DefaultMemoryConfig().DefaultSimilarityThreshold\n\t}\n\n\tvar candidates []*Memory\n\tfor _, mem := range s.memories {\n\t\tif !s.passesAccessFilter(mem, opts) {\n\t\t\tcontinue\n\t\t}"
    },
    {
      "id": "memory/milvus_store-36",
      "cluster": "memory",
      "content": "now := time.Now()\n\tif memory.CreatedAt.IsZero() {\n\t\tmemory.CreatedAt = now\n\t}\n\tmemory.UpdatedAt = now\n\tif memory.LastAccessed.IsZero() {\n\t\tmemory.LastAccessed = now\n\t}\n\n\t// Build metadata JSON (last_accessed and access_count used for retention scoring)\n\tmetadata := map[string]interface{}{\n\t\t\"user_id\":       memory.UserID,\n\t\t\"project_id\":    memory.ProjectID,\n\t\t\"source\":        memory.Source,\n\t\t\"importance\":    memory.Importance,\n\t\t\"access_count\":  memory.AccessCount,\n\t\t\"last_accessed\": memory.LastAccessed.Unix(),\n\t}"
    },
    {
      "id": "memory/testdata/generate_source_dataset-0",
      "cluster": "memory/testdata",
      "content": "// +build ignore\n\n// generate_source_dataset reads Go source files under pkg/ and produces\n// evaluation_dataset.json with real source code chunks as entries.\n//\n// Usage:\n//   go run testdata/generate_source_dataset.go [-out testdata/evaluation_source.json] [-chunksize 300] [-max 120]\n//\n// Each source file is split into chunks of ~chunksize characters at function\n// boundaries (or line boundaries). The package directory is the cluster label."
    },
    {
      "id": "memory/testdata/generate_source_dataset-4",
      "cluster": "memory/testdata",
      "content": "byPkg := map[string][]string{}\n\terr := filepath.Walk(pkgDir, func(path string, info os.FileInfo, err error) error {\n\t\tif err != nil || info.IsDir() {\n\t\t\treturn err\n\t\t}\n\t\tif !strings.HasSuffix(path, \".go\") || strings.HasSuffix(path, \"_test.go\") {\n\t\t\treturn nil\n\t\t}\n\t\trel, _ := filepath.Rel(pkgDir, path)\n\t\tpkg := filepath.Dir(rel)\n\t\tbyPkg[pkg] = append(byPkg[pkg], path)\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"walk error: %v\\n\", err)\n\t\tos.Exit(1)\n\t}"
    },
    {
      "id": "memory/testdata/generate_source_dataset-8",
      "cluster": "memory/testdata",
      "content": "data, err := json.MarshalIndent(ds, \"\", \"  \")\n\tif err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"marshal error: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\tif err := os.WriteFile(*outPath, data, 0644); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"write error: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\tfmt.Fprintf(os.Stderr, \"Wrote %s (%d entries, %d queries)\\n\", *outPath, len(sampled), len(queries))\n}\n\n// chunkFile splits a Go source file into chunks at function boundaries."
    },
    {
      "id": "modeldownload/config_parser-0",
      "cluster": "modeldownload",
      "content": "package modeldownload\n\nimport (\n\t\"fmt\"\n\t\"os\"\n\t\"reflect\"\n\t\"strings\"\n\n\t\"github.com/vllm-project/semantic-router/src/semantic-router/pkg/config\"\n)\n\n// ExtractModelPaths extracts all model paths from the configuration\n// It recursively searches for fields named \"ModelID\", \"Qwen3ModelPath\", \"GemmaModelPath\",\n// or any field ending with \"ModelPath\" (but excludes non-model paths like mapping_path, tools_db_path)"
    },
    {
      "id": "modeldownload/downloader-0",
      "cluster": "modeldownload",
      "content": "package modeldownload\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"os\"\n\t\"os/exec\"\n\t\"strings\"\n\n\t\"github.com/vllm-project/semantic-router/src/semantic-router/pkg/observability/logging\"\n)\n\n// hfCommand stores the detected HuggingFace CLI command (\"hf\" or \"huggingface-cli\")\nvar hfCommand string\n\n// ErrGatedModelSkipped is a sentinel error indicating a gated model was gracefully skipped\nvar ErrGatedModelSkipped = fmt.Errorf(\"gated model skipped\")"
    },
    {
      "id": "modeldownload/downloader-9",
      "cluster": "modeldownload",
      "content": "// Download missing models serially\n\tsuccessCount := 0\n\tskippedCount := 0\n\tfor _, spec := range missing {\n\t\tif err := DownloadModelWithProgress(spec, config); err != nil {\n\t\t\t// Check if this was a gated model that was gracefully skipped\n\t\t\tif errors.Is(err, ErrGatedModelSkipped) || strings.Contains(err.Error(), ErrGatedModelSkipped.Error()) {\n\t\t\t\tskippedCount++\n\t\t\t\tlogging.Infof(\"âœ“ %s (skipped - gated model, HF_TOKEN not available)\", spec.LocalPath)\n\t\t\t\tcontinue\n\t\t\t}"
    },
    {
      "id": "modelselection/benchmark_runner-0",
      "cluster": "modelselection",
      "content": "/*\nCopyright 2025 vLLM Semantic Router.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/"
    },
    {
      "id": "modelselection/config_analyzer-8",
      "cluster": "modelselection",
      "content": "return result\n}\n\n// PrintAnalysisSummary prints a summary of the config analysis\nfunc (r *ConfigAnalysisResult) PrintAnalysisSummary() {\n\tfmt.Println(\"\\n\" + \"=\" + repeatString(\"=\", 59))\n\tfmt.Println(\"MODEL SELECTION CONFIG ANALYSIS\")\n\tfmt.Println(repeatString(\"=\", 60))\n\n\tfmt.Printf(\"\\nðŸ“Š Total decisions analyzed: %d\\n\", r.TotalDecisions)\n\tfmt.Printf(\"   â€¢ Multi-model categories: %d (need selection)\\n\", len(r.MultiModelCategories))\n\tfmt.Printf(\"   â€¢ Single-model categories: %d (no selection needed)\\n\", len(r.SingleModelCategories))"
    },
    {
      "id": "modelselection/selector-24",
      "cluster": "modelselection",
      "content": "// NormalizeVector normalizes a vector to unit length\nfunc NormalizeVector(v []float64) []float64 {\n\tvar norm float64\n\tfor _, val := range v {\n\t\tnorm += val * val\n\t}\n\tnorm = math.Sqrt(norm)\n\n\tif norm == 0 {\n\t\treturn v\n\t}\n\n\tresult := make([]float64, len(v))\n\tfor i, val := range v {\n\t\tresult[i] = val / norm\n\t}\n\treturn result\n}\n\n// Float32ToFloat64 converts float32 slice to float64\nfunc Float32ToFloat64(input []float32) []float64 {"
    },
    {
      "id": "observability/logging/logging-0",
      "cluster": "observability/logging",
      "content": "package logging\n\nimport (\n\t\"os\"\n\t\"strings\"\n\n\t\"go.uber.org/zap\"\n\t\"go.uber.org/zap/zapcore\"\n)\n\n// Config holds logger configuration.\ntype Config struct {\n\t// Level is one of: debug, info, warn, error, dpanic, panic, fatal\n\tLevel string\n\t// Encoding is one of: json, console\n\tEncoding string\n\t// Development enables dev-friendly logging (stacktraces on error, etc.)\n\tDevelopment bool\n\t// AddCaller enables caller annotations."
    },
    {
      "id": "observability/logging/logging-3",
      "cluster": "observability/logging",
      "content": "zcfg.EncoderConfig.EncodeTime = zapcore.TimeEncoderOfLayout(\"2006-01-02T15:04:05\")\n\tzcfg.EncoderConfig.MessageKey = \"msg\"\n\tzcfg.EncoderConfig.LevelKey = \"level\"\n\tzcfg.EncoderConfig.EncodeLevel = zapcore.LowercaseLevelEncoder\n\tzcfg.EncoderConfig.CallerKey = \"caller\"\n\t// Custom caller encoder: only filename:line (no package path)\n\tzcfg.EncoderConfig.EncodeCaller = func(caller zapcore.EntryCaller, enc zapcore.PrimitiveArrayEncoder) {\n\t\t// Extract just the filename from the full path"
    },
    {
      "id": "observability/logging/logging-6",
      "cluster": "observability/logging",
      "content": "cfg := Config{\n\t\tLevel:       getenvDefault(\"SR_LOG_LEVEL\", \"info\"),\n\t\tEncoding:    getenvDefault(\"SR_LOG_ENCODING\", \"json\"),\n\t\tDevelopment: parseBool(getenvDefault(\"SR_LOG_DEVELOPMENT\", \"false\")),\n\t\tAddCaller:   parseBool(getenvDefault(\"SR_LOG_ADD_CALLER\", \"true\")),\n\t}\n\treturn InitLogger(cfg)\n}\n\nfunc getenvDefault(k, d string) string {\n\tv := os.Getenv(k)\n\tif v == \"\" {\n\t\treturn d\n\t}\n\treturn v\n}"
    },
    {
      "id": "observability/metrics/image_gen_metrics-0",
      "cluster": "observability/metrics",
      "content": "package metrics\n\n// RecordImageGenRequest records an image generation request\nfunc RecordImageGenRequest(backend string, status string, latency float64) {\n\tImageGenRequests.WithLabelValues(backend, status).Inc()\n\tif latency \u003e 0 {\n\t\tImageGenLatency.WithLabelValues(backend).Observe(latency)\n\t}\n}"
    },
    {
      "id": "observability/metrics/metrics-36",
      "cluster": "observability/metrics",
      "content": "if reason == \"\" {\n\t\treason = consts.UnknownLabel\n\t}\n\t// Normalize a few common variants to canonical reasons\n\tswitch reason {\n\tcase \"deadline_exceeded\":\n\t\treason = \"timeout\"\n\tcase \"upstream_500\", \"upstream_502\", \"upstream_503\", \"upstream_504\":\n\t\treason = \"upstream_5xx\"\n\tcase \"upstream_400\", \"upstream_401\", \"upstream_403\", \"upstream_404\", \"upstream_429\":\n\t\treason = \"upstream_4xx\"\n\t}\n\tRequestErrorsTotal.WithLabelValues(model, reason).Inc()\n}"
    },
    {
      "id": "observability/metrics/metrics-73",
      "cluster": "observability/metrics",
      "content": "if decisionName == \"\" {\n\t\tdecisionName = consts.UnknownLabel\n\t}\n\tif status == \"\" {\n\t\tstatus = \"unknown\"\n\t}\n\tPluginExecutionTotal.WithLabelValues(pluginType, decisionName, status).Inc()\n\tPluginExecutionLatency.WithLabelValues(pluginType).Observe(latencySeconds)\n}\n\n// RecordPluginError records a plugin execution error\nfunc RecordPluginError(pluginType, errorReason string) {\n\tif pluginType == \"\" {\n\t\tpluginType = consts.UnknownLabel\n\t}"
    },
    {
      "id": "observability/tracing/propagation-0",
      "cluster": "observability/tracing",
      "content": "package tracing\n\nimport (\n\t\"context\"\n\n\t\"go.opentelemetry.io/otel\"\n\t\"go.opentelemetry.io/otel/propagation\"\n)\n\n// InjectTraceContext injects trace context into a map (e.g., HTTP headers)\nfunc InjectTraceContext(ctx context.Context, headers map[string]string) {\n\tpropagator := otel.GetTextMapPropagator()\n\tcarrier := propagation.MapCarrier(headers)\n\tpropagator.Inject(ctx, carrier)\n}\n\n// ExtractTraceContext extracts trace context from a map (e.g., HTTP headers)"
    },
    {
      "id": "observability/tracing/tracing-6",
      "cluster": "observability/tracing",
      "content": "// Create named tracer for the router\n\ttracer = tracerProvider.Tracer(\"semantic-router\")\n\n\treturn nil\n}\n\n// createOTLPExporter creates an OTLP gRPC exporter\nfunc createOTLPExporter(ctx context.Context, cfg TracingConfig) (sdktrace.SpanExporter, error) {\n\topts := []otlptracegrpc.Option{\n\t\totlptracegrpc.WithEndpoint(cfg.ExporterEndpoint),\n\t}\n\n\tif cfg.ExporterInsecure {\n\t\topts = append(opts, otlptracegrpc.WithTLSCredentials(insecure.NewCredentials()))\n\t}"
    },
    {
      "id": "observability/tracing/tracing-15",
      "cluster": "observability/tracing",
      "content": "// StartPluginSpan starts a new span for plugin execution with standard attributes\n// pluginType: the type of plugin (e.g., \"pii\", \"jailbreak\", \"system_prompt\", \"semantic-cache\")\n// decisionName: the decision name this plugin is associated with\n// Returns the new context and span\nfunc StartPluginSpan(ctx context.Context, pluginType string, decisionName string) (context.Context, trace.Span) {\n\tspanCtx, span := StartSpan(ctx, SpanPluginExecution)"
    },
    {
      "id": "openai/filestore-0",
      "cluster": "openai",
      "content": "package openai\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n\t\"mime/multipart\"\n\t\"net/http\"\n\t\"time\"\n\n\t\"github.com/vllm-project/semantic-router/src/semantic-router/pkg/observability/logging\"\n)\n\n// FileStoreClient handles interactions with OpenAI File Store API\ntype FileStoreClient struct {\n\thttpClient *http.Client\n\tbaseURL    string\n\tapiKey     string\n}\n\n// NewFileStoreClient creates a new OpenAI File Store client"
    },
    {
      "id": "openai/vectorstore-0",
      "cluster": "openai",
      "content": "package openai\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n\t\"net/http\"\n\t\"time\"\n\n\t\"github.com/vllm-project/semantic-router/src/semantic-router/pkg/observability/logging\"\n)\n\n// VectorStoreClient handles interactions with OpenAI Vector Store API\ntype VectorStoreClient struct {\n\thttpClient *http.Client\n\tbaseURL    string\n\tapiKey     string\n}\n\n// NewVectorStoreClient creates a new OpenAI Vector Store client"
    },
    {
      "id": "openai/vectorstore-16",
      "cluster": "openai",
      "content": "req.Header.Set(\"Authorization\", \"Bearer \"+c.apiKey)\n\n\tresp, err := c.httpClient.Do(req)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to delete vector store: %w\", err)\n\t}\n\tdefer resp.Body.Close()\n\n\tif resp.StatusCode != http.StatusOK {\n\t\tbody, _ := io.ReadAll(io.LimitReader(resp.Body, 1024))\n\t\treturn fmt.Errorf(\"delete vector store failed with status %d: %s\", resp.StatusCode, string(body))\n\t}\n\n\tlogging.Infof(\"Deleted vector store %s\", vectorStoreID)\n\treturn nil\n}"
    },
    {
      "id": "ratelimit/chain-0",
      "cluster": "ratelimit",
      "content": "package ratelimit\n\nimport (\n\t\"fmt\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/vllm-project/semantic-router/src/semantic-router/pkg/observability/logging\"\n)\n\n// RateLimitResolver chains multiple Providers and evaluates rate limits\n// using first-deny semantics: every provider is checked and if any provider\n// denies, the request is rejected with a 429.\n//\n// Typical chain order:\n//  1. EnvoyRLSProvider  (global limits via external Envoy Rate Limit Service)"
    },
    {
      "id": "ratelimit/envoy_provider-3",
      "cluster": "ratelimit",
      "content": "return \u0026EnvoyRLSProvider{\n\t\tclient:  client,\n\t\tconn:    conn,\n\t\tdomain:  domain,\n\t\ttimeout: 2 * time.Second,\n\t}, nil\n}\n\nfunc (p *EnvoyRLSProvider) Name() string {\n\treturn \"envoy-ratelimit\"\n}\n\n// Check sends a ShouldRateLimit request to the external RLS.\n// Descriptors are built from the request context: user_id, model, and each group.\nfunc (p *EnvoyRLSProvider) Check(ctx Context) (*Decision, error) {"
    },
    {
      "id": "ratelimit/local_provider-7",
      "cluster": "ratelimit",
      "content": "if mostRestrictiveLimit \u003c 0 || int64(rule.TokensPerUnit) \u003c mostRestrictiveLimit {\n\t\t\t\tmostRestrictiveLimit = int64(rule.TokensPerUnit)\n\t\t\t}\n\t\t\tif earliestReset.IsZero() || resetAt.Before(earliestReset) {\n\t\t\t\tearliestReset = resetAt\n\t\t\t}\n\t\t}\n\t}\n\n\tif mostRestrictiveRemaining \u003c 0 {\n\t\tmostRestrictiveRemaining = 0\n\t}\n\tif mostRestrictiveLimit \u003c 0 {\n\t\tmostRestrictiveLimit = 0\n\t}\n\n\treturn \u0026Decision{\n\t\tAllowed:   true,\n\t\tRemaining: mostRestrictiveRemaining,\n\t\tLimit:     mostRestrictiveLimit,\n\t\tResetAt:   earliestReset,\n\t\tProvider:  l.Name(),\n\t}, nil\n}"
    },
    {
      "id": "responseapi/id-0",
      "cluster": "responseapi",
      "content": "package responseapi\n\nimport (\n\t\"crypto/rand\"\n\t\"encoding/hex\"\n\t\"fmt\"\n\t\"strings\"\n)\n\n// ID prefixes following OpenAI conventions\nconst (\n\tResponseIDPrefix     = \"resp_\"\n\tItemIDPrefix         = \"item_\"\n\tMessageIDPrefix      = \"msg_\"\n\tConversationIDPrefix = \"conv_\"\n)\n\n// GenerateResponseID generates a new response ID with the resp_ prefix.\nfunc GenerateResponseID() string {\n\treturn ResponseIDPrefix + generateRandomID(24)\n}"
    },
    {
      "id": "responseapi/translator-11",
      "cluster": "responseapi",
      "content": "}\n\n\t\t// Handle tool calls\n\t\tfor _, tc := range msg.ToolCalls {\n\t\t\toutput = append(output, OutputItem{\n\t\t\t\tType:      ItemTypeFunctionCall,\n\t\t\t\tID:        GenerateItemID(),\n\t\t\t\tCallID:    tc.ID,\n\t\t\t\tName:      tc.Function.Name,\n\t\t\t\tArguments: tc.Function.Arguments,\n\t\t\t\tStatus:    StatusCompleted,\n\t\t\t})\n\t\t}\n\t}\n\n\tvar usage *Usage\n\tif resp.Usage != nil {\n\t\tusage = \u0026Usage{\n\t\t\tInputTokens:  resp.Usage.PromptTokens,\n\t\t\tOutputTokens: resp.Usage.CompletionTokens,\n\t\t\tTotalTokens:  resp.Usage.TotalTokens,\n\t\t}"
    },
    {
      "id": "responseapi/types-8",
      "cluster": "responseapi",
      "content": "MaxOutputTokens *int `json:\"max_output_tokens,omitempty\"`\n\n\t// Tools available\n\tTools []Tool `json:\"tools,omitempty\"`\n\n\t// ToolChoice setting\n\tToolChoice interface{} `json:\"tool_choice,omitempty\"`\n\n\t// ParallelToolCalls setting\n\tParallelToolCalls *bool `json:\"parallel_tool_calls,omitempty\"`\n\n\t// Reasoning information for reasoning models\n\tReasoning *Reasoning `json:\"reasoning,omitempty\"`\n\n\t// Text configuration"
    },
    {
      "id": "responsestore/errors-0",
      "cluster": "responsestore",
      "content": "package responsestore\n\nimport \"errors\"\n\n// Common errors returned by ResponseStore implementations.\nvar (\n\t// ErrNotFound is returned when a requested item doesn't exist.\n\tErrNotFound = errors.New(\"item not found\")\n\n\t// ErrAlreadyExists is returned when trying to create an item that already exists.\n\tErrAlreadyExists = errors.New(\"item already exists\")\n\n\t// ErrStoreDisabled is returned when the store is not enabled."
    },
    {
      "id": "responsestore/memory_store-2",
      "cluster": "responsestore",
      "content": "go store.cleanupExpired()\n\treturn store, nil\n}\n\nfunc (m *MemoryStore) IsEnabled() bool { return m.enabled }\n\nfunc (m *MemoryStore) CheckConnection(ctx context.Context) error {\n\tif !m.enabled {\n\t\treturn ErrStoreDisabled\n\t}\n\treturn nil\n}\n\nfunc (m *MemoryStore) Close() error {\n\tm.mu.Lock()\n\tdefer m.mu.Unlock()\n\tm.responses = nil\n\tm.conversations = nil\n\treturn nil\n}\n\nfunc (m *MemoryStore) StoreResponse(ctx context.Context, response *responseapi.StoredResponse) error {"
    },
    {
      "id": "responsestore/redis_store-13",
      "cluster": "responsestore",
      "content": "if cfg.TLSCAPath != \"\" {\n\t\t\tcaCert, err := os.ReadFile(cfg.TLSCAPath)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"failed to read CA certificate: %w\", err)\n\t\t\t}\n\t\t\tcaCertPool := x509.NewCertPool()\n\t\t\tif !caCertPool.AppendCertsFromPEM(caCert) {\n\t\t\t\treturn nil, fmt.Errorf(\"failed to parse CA certificate\")\n\t\t\t}\n\t\t\ttlsConfig.RootCAs = caCertPool\n\t\t}\n\n\t\tlogging.Debugf(\"RedisStore: TLS enabled\")\n\t}"
    },
    {
      "id": "routerreplay/recorder-0",
      "cluster": "routerreplay",
      "content": "package routerreplay\n\nimport (\n\t\"context\"\n\t\"time\"\n\n\t\"github.com/vllm-project/semantic-router/src/semantic-router/pkg/routerreplay/store\"\n)\n\nconst (\n\tDefaultMaxRecords   = 200\n\tDefaultMaxBodyBytes = 4096 // 4KB\n)\n\ntype (\n\tSignal        = store.Signal\n\tRoutingRecord = store.Record\n)\n\ntype Recorder struct {\n\tstorage store.Storage\n\n\tmaxBodyBytes int\n\n\tcaptureRequestBody  bool\n\tcaptureResponseBody bool\n}"
    },
    {
      "id": "routerreplay/recorder-3",
      "cluster": "routerreplay",
      "content": "if r.captureRequestBody \u0026\u0026 len(rec.RequestBody) \u003e r.maxBodyBytes {\n\t\trec.RequestBody = rec.RequestBody[:r.maxBodyBytes]\n\t\trec.RequestBodyTruncated = true\n\t}\n\n\tif r.captureResponseBody \u0026\u0026 len(rec.ResponseBody) \u003e r.maxBodyBytes {\n\t\trec.ResponseBody = rec.ResponseBody[:r.maxBodyBytes]\n\t\trec.ResponseBodyTruncated = true\n\t}\n\n\tctx := context.Background()\n\treturn r.storage.Add(ctx, rec)\n}\n\nfunc (r *Recorder) UpdateStatus(id string, status int, fromCache bool, streaming bool) error {"
    },
    {
      "id": "routerreplay/recorder-6",
      "cluster": "routerreplay",
      "content": "// GetRecord returns a copy of the record with the given ID.\nfunc (r *Recorder) GetRecord(id string) (RoutingRecord, bool) {\n\tctx := context.Background()\n\trec, found, err := r.storage.Get(ctx, id)\n\tif err != nil {\n\t\treturn RoutingRecord{}, false\n\t}\n\treturn rec, found\n}\n\nfunc (r *Recorder) ListAllRecords() []RoutingRecord {\n\tctx := context.Background()\n\trecords, err := r.storage.List(ctx)\n\tif err != nil {\n\t\treturn []RoutingRecord{}\n\t}"
    },
    {
      "id": "routerreplay/store/factory-0",
      "cluster": "routerreplay/store",
      "content": "package store\n\nimport (\n\t\"fmt\"\n)\n\n// NewStorage creates a new storage backend based on the provided configuration.\nfunc NewStorage(cfg *Config) (Storage, error) {\n\tif cfg == nil {\n\t\treturn nil, fmt.Errorf(\"storage config is required\")\n\t}\n\n\tbackend := cfg.Backend\n\tif backend == \"\" {\n\t\tbackend = \"memory\"\n\t}\n\n\tswitch backend {\n\tcase \"memory\":\n\t\tmaxRecords := 200\n\t\tif cfg.MaxBodyBytes \u003e 0 {\n\t\t\tmaxRecords = cfg.MaxBodyBytes\n\t\t}"
    },
    {
      "id": "routerreplay/store/milvus-20",
      "cluster": "routerreplay/store",
      "content": "// Get existing record\n\trecord, found, err := m.Get(ctx, id)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif !found {\n\t\treturn fmt.Errorf(\"record with ID %s not found\", id)\n\t}\n\n\t// Update fields\n\tif status != 0 {\n\t\trecord.ResponseStatus = status\n\t}\n\trecord.FromCache = record.FromCache || fromCache\n\trecord.Streaming = record.Streaming || streaming\n\n\t// Delete old record and insert updated one\n\treturn m.upsertRecord(ctx, record)\n}"
    },
    {
      "id": "routerreplay/store/postgres-25",
      "cluster": "routerreplay/store",
      "content": "return fn()\n}\n\n// cleanupOldRecords removes records older than the TTL.\nfunc (p *PostgresStore) cleanupOldRecords(ctx context.Context) error {\n\tif p.ttl == 0 {\n\t\treturn nil\n\t}\n\n\t//nolint:gosec // tableName is validated during store creation, ttl is duration\n\tquery := fmt.Sprintf(`\n\t\tDELETE FROM %s\n\t\tWHERE created_at \u003c NOW() - INTERVAL '%d seconds'\n\t`, p.tableName, int(p.ttl.Seconds()))\n\n\t_, err := p.db.ExecContext(ctx, query)\n\treturn err\n}"
    },
    {
      "id": "selection/automix-0",
      "cluster": "selection",
      "content": "/*\nCopyright 2025 vLLM Semantic Router.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/"
    },
    {
      "id": "selection/gmtrouter-48",
      "cluster": "selection",
      "content": "// computePersonalizedScores computes scores for each model based on user preferences\nfunc (g *GMTRouterSelector) computePersonalizedScores(userID string, selCtx *SelectionContext) map[string]float64 {\n\tg.userMu.RLock()\n\tdefer g.userMu.RUnlock()\n\n\tscores := make(map[string]float64)\n\tstate := g.userStates[userID]\n\n\tfor _, model := range selCtx.CandidateModels {\n\t\tbaseScore := g.getDefaultModelScore(model.Model)"
    },
    {
      "id": "selection/rl_driven-28",
      "cluster": "selection",
      "content": "// Requires external server: src/training/rl_model_selection/router_r1_server.py\n\tif cfg.EnableLLMRouting \u0026\u0026 cfg.RouterR1ServerURL != \"\" {\n\t\tselector.routerR1Client = NewRouterR1Client(cfg.RouterR1ServerURL)\n\t\tlogging.Infof(\"[RLDrivenSelector] Router-R1 LLM routing enabled, server: %s\", cfg.RouterR1ServerURL)\n\n\t\t// Verify connectivity\n\t\tctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\n\t\tdefer cancel()\n\t\tif err := selector.routerR1Client.HealthCheck(ctx); err != nil {\n\t\t\tlogging.Warnf(\"[RLDrivenSelector] Router-R1 server not reachable: %v (will retry on use)\", err)\n\t\t} else {\n\t\t\tlogging.Infof(\"[RLDrivenSelector] Router-R1 server connected successfully\")\n\t\t}"
    },
    {
      "id": "services/classification-0",
      "cluster": "services",
      "content": "package services\n\nimport (\n\t\"fmt\"\n\t\"os\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/vllm-project/semantic-router/src/semantic-router/pkg/classification\"\n\t\"github.com/vllm-project/semantic-router/src/semantic-router/pkg/config\"\n\t\"github.com/vllm-project/semantic-router/src/semantic-router/pkg/decision\"\n\t\"github.com/vllm-project/semantic-router/src/semantic-router/pkg/observability/logging\"\n)\n\n// Global classification service instance"
    },
    {
      "id": "services/classification-25",
      "cluster": "services",
      "content": "var decisionResult *decision.DecisionResult\n\tvar err error\n\tif s.config != nil \u0026\u0026 len(s.config.IntelligentRouting.Decisions) \u003e 0 {\n\t\tdecisionResult, err = s.classifier.EvaluateDecisionWithEngine(signals)\n\t\tif err != nil {\n\t\t\t// Log error but continue with classification\n\t\t\t// Note: \"no decisions configured\" error is expected when decisions list is empty\n\t\t\tif !strings.Contains(err.Error(), \"no decisions configured\") {\n\t\t\t\tlogging.Warnf(\"Decision evaluation failed, continuing with classification: %v\", err)\n\t\t\t}"
    },
    {
      "id": "services/classification-50",
      "cluster": "services",
      "content": "type FactCheckOptions struct {\n\tConfidenceThreshold float64 `json:\"confidence_threshold,omitempty\"`\n}\n\n// FactCheckResponse represents the response from fact-check classification\ntype FactCheckResponse struct {\n\tNeedsFactCheck   bool    `json:\"needs_fact_check\"`\n\tLabel            string  `json:\"label\"`\n\tConfidence       float64 `json:\"confidence\"`\n\tProcessingTimeMs int64   `json:\"processing_time_ms\"`\n}"
    },
    {
      "id": "tools/relevance-0",
      "cluster": "tools",
      "content": "// Package tools provides tool selection and filtering capabilities\n// for the semantic router.\npackage tools\n\nimport (\n\t\"sort\"\n\t\"strings\"\n\t\"unicode\"\n\n\t\"github.com/openai/openai-go\"\n\n\t\"github.com/vllm-project/semantic-router/src/semantic-router/pkg/config\"\n)\n\n// FilterAndRankTools applies advanced filtering and ranking to tool candidates.\nfunc FilterAndRankTools(query string, candidates []ToolSimilarity, topK int, advanced *config.AdvancedToolFilteringConfig, selectedCategory string) []openai.ChatCompletionToolParam {"
    },
    {
      "id": "tools/relevance-12",
      "cluster": "tools",
      "content": "selectedCategory = strings.ToLower(strings.TrimSpace(selectedCategory))\n\tfiltered := make([]ToolSimilarity, 0, len(candidates))\n\tfor _, candidate := range candidates {\n\t\tcandidateCategory := strings.ToLower(strings.TrimSpace(candidate.Entry.Category))\n\t\tif candidateCategory == selectedCategory {\n\t\t\tfiltered = append(filtered, candidate)\n\t\t}\n\t}\n\n\tif len(filtered) == 0 {\n\t\treturn candidates\n\t}\n\treturn filtered\n}"
    },
    {
      "id": "tools/tools-5",
      "cluster": "tools",
      "content": "logging.Infof(\"[Tool Selection] Loading tools and generating embeddings with concurrent processing (model: %s, dimension: %d)...\",\n\t\tdb.modelType, db.targetDim)\n\n\t// Use worker pool for concurrent embedding generation\n\tnumWorkers := runtime.NumCPU() * 2\n\tif numWorkers \u003e len(toolEntries) {\n\t\tnumWorkers = len(toolEntries)\n\t}\n\n\ttype result struct {\n\t\tentry ToolEntry\n\t\terr   error\n\t}\n\n\tresultChan := make(chan result, len(toolEntries))\n\tentryChan := make(chan ToolEntry, len(toolEntries))"
    },
    {
      "id": "utils/entropy/entropy-0",
      "cluster": "utils/entropy",
      "content": "package entropy\n\nimport (\n\t\"cmp\"\n\t\"math\"\n\t\"slices\"\n)\n\n// EntropyResult contains the results of entropy-based analysis\ntype EntropyResult struct {\n\tEntropy           float64 // Shannon entropy of the probability distribution\n\tNormalizedEntropy float64 // Entropy normalized to [0,1] range\n\tCertainty         float64 // Inverse of normalized entropy (1 - normalized_entropy)\n\tUncertaintyLevel  string  // Human-readable uncertainty level\n}"
    },
    {
      "id": "utils/entropy/entropy-5",
      "cluster": "utils/entropy",
      "content": "// MakeEntropyBasedReasoningDecision implements the entropy-based reasoning strategy\nfunc MakeEntropyBasedReasoningDecision(\n\tprobabilities []float32,\n\tcategoryNames []string,\n\tcategoryReasoningMap map[string]bool,\n\tbaseConfidenceThreshold float64,\n) ReasoningDecision {\n\tif len(probabilities) == 0 || len(categoryNames) == 0 {\n\t\treturn ReasoningDecision{\n\t\t\tUseReasoning:     false,\n\t\t\tConfidence:       0.0,\n\t\t\tDecisionReason:   \"no_classification_data\",\n\t\t\tFallbackStrategy: \"default_no_reasoning\",\n\t\t}"
    },
    {
      "id": "utils/entropy/entropy-10",
      "cluster": "utils/entropy",
      "content": "return ReasoningDecision{\n\t\t\t\tUseReasoning:     useReasoning,\n\t\t\t\tConfidence:       topConfidence * confidenceMultiplier,\n\t\t\t\tDecisionReason:   entropyResult.UncertaintyLevel + \"_uncertainty_trust_classification\",\n\t\t\t\tFallbackStrategy: \"trust_top_category\",\n\t\t\t\tTopCategories:    topCategories,\n\t\t\t}\n\t\t}\n\n\t\t// Category not in reasoning map - default to no reasoning\n\t\treturn ReasoningDecision{\n\t\t\tUseReasoning:     false,\n\t\t\tConfidence:       topConfidence * 0.8,\n\t\t\tDecisionReason:   \"category_not_in_reasoning_map\",\n\t\t\tFallbackStrategy: \"unknown_category_default\",\n\t\t\tTopCategories:    topCategories,\n\t\t}"
    },
    {
      "id": "utils/http/response-0",
      "cluster": "utils/http",
      "content": "package http\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"strings\"\n\t\"time\"\n\n\tcore \"github.com/envoyproxy/go-control-plane/envoy/config/core/v3\"\n\text_proc \"github.com/envoyproxy/go-control-plane/envoy/service/ext_proc/v3\"\n\ttypev3 \"github.com/envoyproxy/go-control-plane/envoy/type/v3\"\n\t\"github.com/openai/openai-go\"\n\n\t\"github.com/vllm-project/semantic-router/src/semantic-router/pkg/headers\"\n\t\"github.com/vllm-project/semantic-router/src/semantic-router/pkg/observability/logging\"\n\t\"github.com/vllm-project/semantic-router/src/semantic-router/pkg/observability/metrics\"\n)"
    },
    {
      "id": "utils/http/response-10",
      "cluster": "utils/http",
      "content": "contentType = \"application/json\"\n\n\t\topenAIResponse := openai.ChatCompletion{\n\t\t\tID:      fmt.Sprintf(\"chatcmpl-jailbreak-blocked-%d\", unixTimeStep),\n\t\t\tObject:  \"chat.completion\",\n\t\t\tCreated: unixTimeStep,\n\t\t\tModel:   \"security-filter\",\n\t\t\tChoices: []openai.ChatCompletionChoice{\n\t\t\t\t{\n\t\t\t\t\tIndex: 0,\n\t\t\t\t\tMessage: openai.ChatCompletionMessage{\n\t\t\t\t\t\tRole:    \"assistant\",\n\t\t\t\t\t\tContent: fmt.Sprintf(\"I cannot process this request as it appears to contain a potential jailbreak attempt (type: %s, confidence: %.3f). Please rephrase your request in a way that complies with our usage policies.\", jailbreakType, confidence),\n\t\t\t\t\t},\n\t\t\t\t\tFinishReason: \"content_filter\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tUsage: openai.CompletionUsage{\n\t\t\t\tPromptTokens:     0,\n\t\t\t\tCompletionTokens: 0,\n\t\t\t\tTotalTokens:      0,\n\t\t\t},\n\t\t}"
    },
    {
      "id": "utils/http/response-20",
      "cluster": "utils/http",
      "content": "// Extract content and split into chunks\n\t\t\t\t\tcontent := cachedCompletion.Choices[0].Message.Content\n\t\t\t\t\tchunks := splitContentIntoChunks(content)\n\n\t\t\t\t\tif len(chunks) == 0 {\n\t\t\t\t\t\t// Fallback: if splitting failed, use original content as single chunk\n\t\t\t\t\t\tchunks = []string{content}\n\t\t\t\t\t}\n\n\t\t\t\t\t// Build SSE response with multiple chunks\n\t\t\t\t\tvar sseChunks []string\n\n\t\t\t\t\t// Send incremental content chunks"
    },
    {
      "id": "utils/pii/policy-0",
      "cluster": "utils/pii",
      "content": "package pii\n\nimport (\n\t\"slices\"\n\n\t\"github.com/vllm-project/semantic-router/src/semantic-router/pkg/config\"\n\t\"github.com/vllm-project/semantic-router/src/semantic-router/pkg/observability/logging\"\n)\n\n// PolicyChecker handles PII policy validation based on decisions\ntype PolicyChecker struct {\n\tConfig *config.RouterConfig\n}\n\n// IsPIIEnabled checks if PII detection is enabled for a given decision\nfunc (c *PolicyChecker) IsPIIEnabled(decisionName string) bool {"
    },
    {
      "id": "utils/pii/policy-2",
      "cluster": "utils/pii",
      "content": "// PII detection is enabled if the plugin is enabled\n\treturn piiConfig.Enabled\n}\n\n// NewPolicyChecker creates a new PII policy checker\nfunc NewPolicyChecker(cfg *config.RouterConfig) *PolicyChecker {\n\treturn \u0026PolicyChecker{\n\t\tConfig: cfg,\n\t}\n}\n\n// CheckPolicy checks if the detected PII types are allowed for the given decision\nfunc (pc *PolicyChecker) CheckPolicy(decisionName string, detectedPII []string) (bool, []string, error) {"
    },
    {
      "id": "utils/pii/policy-4",
      "cluster": "utils/pii",
      "content": "for _, piiType := range detectedPII {\n\t\tif piiType == \"NO_PII\" {\n\t\t\tcontinue // Skip non-PII content\n\t\t}\n\n\t\t// If allow_by_default is true, all PII types are allowed\n\t\tif policy.AllowByDefault {\n\t\t\tcontinue\n\t\t}\n\n\t\t// If allow_by_default is false, check if this PII type is explicitly allowed\n\t\t// Support both exact matches and BIO-tag stripping (B-PERSON, I-PERSON â†’ PERSON)\n\t\tisAllowed := isPIITypeAllowed(piiType, policy.PIITypes)\n\t\tif !isAllowed {\n\t\t\tdeniedPII = append(deniedPII, piiType)\n\t\t}"
    },
    {
      "id": "utils/tls/tls-0",
      "cluster": "utils/tls",
      "content": "package tls\n\nimport (\n\t\"crypto/rand\"\n\t\"crypto/rsa\"\n\t\"crypto/tls\"\n\t\"crypto/x509\"\n\t\"crypto/x509/pkix\"\n\t\"encoding/pem\"\n\t\"fmt\"\n\t\"math/big\"\n\t\"time\"\n)\n\n// CreateSelfSignedTLSCertificate creates a self-signed cert the server can use to serve TLS.\nfunc CreateSelfSignedTLSCertificate() (tls.Certificate, error) {\n\tserialNumberLimit := new(big.Int).Lsh(big.NewInt(1), 128)\n\tserialNumber, err := rand.Int(rand.Reader, serialNumberLimit)\n\tif err != nil {\n\t\treturn tls.Certificate{}, fmt.Errorf(\"error creating serial number: %w\", err)\n\t}"
    },
    {
      "id": "utils/tls/tls-1",
      "cluster": "utils/tls",
      "content": "now := time.Now()\n\tnotBefore := now.UTC()\n\ttemplate := x509.Certificate{\n\t\tSerialNumber: serialNumber,\n\t\tSubject: pkix.Name{\n\t\t\tOrganization: []string{\"Inference Ext\"},\n\t\t},\n\t\tNotBefore:             notBefore,\n\t\tNotAfter:              now.Add(time.Hour * 24 * 365 * 10).UTC(), // 10 years\n\t\tKeyUsage:              x509.KeyUsageKeyEncipherment | x509.KeyUsageDigitalSignature,\n\t\tExtKeyUsage:           []x509.ExtKeyUsage{x509.ExtKeyUsageServerAuth},\n\t\tBasicConstraintsValid: true,\n\t}"
    },
    {
      "id": "utils/tls/tls-2",
      "cluster": "utils/tls",
      "content": "priv, err := rsa.GenerateKey(rand.Reader, 4096)\n\tif err != nil {\n\t\treturn tls.Certificate{}, fmt.Errorf(\"error generating key: %w\", err)\n\t}\n\n\tderBytes, err := x509.CreateCertificate(rand.Reader, \u0026template, \u0026template, \u0026priv.PublicKey, priv)\n\tif err != nil {\n\t\treturn tls.Certificate{}, fmt.Errorf(\"error creating certificate: %w\", err)\n\t}\n\n\tcertBytes := pem.EncodeToMemory(\u0026pem.Block{Type: \"CERTIFICATE\", Bytes: derBytes})"
    },
    {
      "id": "vectorstore/candle_embedder-0",
      "cluster": "vectorstore",
      "content": "//go:build !windows \u0026\u0026 cgo\n\n/*\nCopyright 2025 vLLM Semantic Router.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/"
    },
    {
      "id": "vectorstore/llama_stack_backend-1",
      "cluster": "vectorstore",
      "content": "package vectorstore\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n\t\"net/http\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/vllm-project/semantic-router/src/semantic-router/pkg/observability/logging\"\n)\n\n// LlamaStackBackendConfig holds configuration for the Llama Stack backend.\ntype LlamaStackBackendConfig struct {\n\t// Endpoint is the base URL of the Llama Stack server (e.g. \"http://localhost:8321\")."
    },
    {
      "id": "vectorstore/memory_backend-17",
      "cluster": "vectorstore",
      "content": "}\n\n\treturn results, nil\n}\n\n// Close is a no-op for the in-memory backend.\nfunc (m *MemoryBackend) Close() error {\n\treturn nil\n}\n\n// cosineSimilarity computes the cosine similarity between two vectors.\nfunc cosineSimilarity(a, b []float32) float64 {\n\tif len(a) != len(b) || len(a) == 0 {\n\t\treturn 0\n\t}\n\n\tvar dot, normA, normB float64\n\tfor i := range a {\n\t\tdot += float64(a[i]) * float64(b[i])\n\t\tnormA += float64(a[i]) * float64(a[i])\n\t\tnormB += float64(b[i]) * float64(b[i])\n\t}\ndenom := math.Sqrt(normA) * math.Sqrt(normB)\n\tif denom == 0 {\n\t\treturn 0\n\t}\n\treturn dot / denom\n}"
    }
  ],
  "queries": [
    {
      "query": "How does the anthropic package work and what are its main functions?",
      "target_cluster": "anthropic"
    },
    {
      "query": "How does the apis/vllm.ai/v1alpha1 package work and what are its main functions?",
      "target_cluster": "apis/vllm.ai/v1alpha1"
    },
    {
      "query": "How does the apiserver package work and what are its main functions?",
      "target_cluster": "apiserver"
    },
    {
      "query": "How does the authz package work and what are its main functions?",
      "target_cluster": "authz"
    },
    {
      "query": "How does the cache package work and what are its main functions?",
      "target_cluster": "cache"
    },
    {
      "query": "How does the classification package work and what are its main functions?",
      "target_cluster": "classification"
    },
    {
      "query": "How does the config package work and what are its main functions?",
      "target_cluster": "config"
    },
    {
      "query": "How does the consts package work and what are its main functions?",
      "target_cluster": "consts"
    },
    {
      "query": "How does the decision package work and what are its main functions?",
      "target_cluster": "decision"
    },
    {
      "query": "How does the extproc package work and what are its main functions?",
      "target_cluster": "extproc"
    },
    {
      "query": "How does the headers package work and what are its main functions?",
      "target_cluster": "headers"
    },
    {
      "query": "How does the hnsw package work and what are its main functions?",
      "target_cluster": "hnsw"
    },
    {
      "query": "How does the imagegen package work and what are its main functions?",
      "target_cluster": "imagegen"
    },
    {
      "query": "How does the k8s package work and what are its main functions?",
      "target_cluster": "k8s"
    },
    {
      "query": "How does the latency package work and what are its main functions?",
      "target_cluster": "latency"
    },
    {
      "query": "How does the logo package work and what are its main functions?",
      "target_cluster": "logo"
    },
    {
      "query": "How does the looper package work and what are its main functions?",
      "target_cluster": "looper"
    },
    {
      "query": "How does the mcp package work and what are its main functions?",
      "target_cluster": "mcp"
    },
    {
      "query": "How does the mcp/api package work and what are its main functions?",
      "target_cluster": "mcp/api"
    },
    {
      "query": "How does the memory package work and what are its main functions?",
      "target_cluster": "memory"
    },
    {
      "query": "How does the memory/testdata package work and what are its main functions?",
      "target_cluster": "memory/testdata"
    },
    {
      "query": "How does the modeldownload package work and what are its main functions?",
      "target_cluster": "modeldownload"
    },
    {
      "query": "How does the modelselection package work and what are its main functions?",
      "target_cluster": "modelselection"
    },
    {
      "query": "How does the observability/logging package work and what are its main functions?",
      "target_cluster": "observability/logging"
    },
    {
      "query": "How does the observability/metrics package work and what are its main functions?",
      "target_cluster": "observability/metrics"
    },
    {
      "query": "How does the observability/tracing package work and what are its main functions?",
      "target_cluster": "observability/tracing"
    },
    {
      "query": "How does the openai package work and what are its main functions?",
      "target_cluster": "openai"
    },
    {
      "query": "How does the ratelimit package work and what are its main functions?",
      "target_cluster": "ratelimit"
    },
    {
      "query": "How does the responseapi package work and what are its main functions?",
      "target_cluster": "responseapi"
    },
    {
      "query": "How does the responsestore package work and what are its main functions?",
      "target_cluster": "responsestore"
    },
    {
      "query": "How does the routerreplay package work and what are its main functions?",
      "target_cluster": "routerreplay"
    },
    {
      "query": "How does the routerreplay/store package work and what are its main functions?",
      "target_cluster": "routerreplay/store"
    },
    {
      "query": "How does the selection package work and what are its main functions?",
      "target_cluster": "selection"
    },
    {
      "query": "How does the services package work and what are its main functions?",
      "target_cluster": "services"
    },
    {
      "query": "How does the tools package work and what are its main functions?",
      "target_cluster": "tools"
    },
    {
      "query": "How does the utils/entropy package work and what are its main functions?",
      "target_cluster": "utils/entropy"
    },
    {
      "query": "How does the utils/http package work and what are its main functions?",
      "target_cluster": "utils/http"
    },
    {
      "query": "How does the utils/pii package work and what are its main functions?",
      "target_cluster": "utils/pii"
    },
    {
      "query": "How does the utils/tls package work and what are its main functions?",
      "target_cluster": "utils/tls"
    },
    {
      "query": "How does the vectorstore package work and what are its main functions?",
      "target_cluster": "vectorstore"
    }
  ]
}