{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "721ab59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==2.5.0\n",
      "  Downloading torch-2.5.0-cp312-cp312-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Collecting torchvision==0.20.0\n",
      "  Downloading torchvision-0.20.0-cp312-cp312-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: filelock in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from torch==2.5.0) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from torch==2.5.0) (4.15.0)\n",
      "Requirement already satisfied: networkx in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from torch==2.5.0) (3.6)\n",
      "Requirement already satisfied: jinja2 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from torch==2.5.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from torch==2.5.0) (2025.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.5.0)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.5.0)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.5.0)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.0)\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.5.0)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.5.0)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.5.0)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.5.0)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.5.0)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch==2.5.0)\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch==2.5.0)\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.5.0)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.1.0 (from torch==2.5.0)\n",
      "  Downloading triton-3.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: setuptools in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from torch==2.5.0) (80.9.0)\n",
      "Collecting sympy==1.13.1 (from torch==2.5.0)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from torchvision==0.20.0) (2.3.5)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.20.0)\n",
      "  Downloading pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from sympy==1.13.1->torch==2.5.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from jinja2->torch==2.5.0) (3.0.3)\n",
      "Downloading torch-2.5.0-cp312-cp312-manylinux1_x86_64.whl (906.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m  \u001b[33m0:00:30\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.20.0-cp312-cp312-manylinux1_x86_64.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m  \u001b[33m0:00:09\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.6/209.6 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m  \u001b[33m0:00:05\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, sympy, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision\n",
      "\u001b[2K  Attempting uninstall: triton\n",
      "\u001b[2K    Found existing installation: triton 3.5.1\n",
      "\u001b[2K    Uninstalling triton-3.5.1:━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/17\u001b[0m [triton]\n",
      "\u001b[2K      Successfully uninstalled triton-3.5.1━\u001b[0m \u001b[32m 0/17\u001b[0m [triton]\n",
      "\u001b[2K  Attempting uninstall: sympy━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/17\u001b[0m [triton]\n",
      "\u001b[2K    Found existing installation: sympy 1.14.0[0m \u001b[32m 0/17\u001b[0m [triton]\n",
      "\u001b[2K    Uninstalling sympy-1.14.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/17\u001b[0m [sympy]\n",
      "\u001b[2K      Successfully uninstalled sympy-1.14.0━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/17\u001b[0m [sympy]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvtx-cu12━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/17\u001b[0m [pillow]\n",
      "\u001b[2K    Found existing installation: nvidia-nvtx-cu12 12.8.90━━━━━\u001b[0m \u001b[32m 2/17\u001b[0m [pillow]\n",
      "\u001b[2K    Uninstalling nvidia-nvtx-cu12-12.8.90:━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/17\u001b[0m [nvidia-nvtx-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvtx-cu12-12.8.90━━━━━━━\u001b[0m \u001b[32m 3/17\u001b[0m [nvidia-nvtx-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvjitlink-cu12━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/17\u001b[0m [nvidia-nvtx-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\u001b[0m \u001b[32m 3/17\u001b[0m [nvidia-nvtx-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-nvjitlink-cu12-12.8.93:━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/17\u001b[0m [nvidia-nvtx-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93━━━━━━\u001b[0m \u001b[32m 4/17\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nccl-cu12━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/17\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-nccl-cu12 2.27.5━━━━━━━━━━\u001b[0m \u001b[32m 5/17\u001b[0m [nvidia-nccl-cu12]]\n",
      "\u001b[2K    Uninstalling nvidia-nccl-cu12-2.27.5:━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/17\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nccl-cu12-2.27.5━━━━━━━━\u001b[0m \u001b[32m 5/17\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-curand-cu12━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/17\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.9.90━\u001b[0m \u001b[32m 5/17\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.9.90:━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/17\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.9.90━━━\u001b[0m \u001b[32m 5/17\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cufft-cu12━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/17\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.3.3.83━━\u001b[0m \u001b[32m 6/17\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cufft-cu12-11.3.3.83:━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/17\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83━━━━\u001b[0m \u001b[32m 6/17\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/17\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.8.90m \u001b[32m 7/17\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.8.90:━━━━━━━━━━━━\u001b[0m \u001b[32m 7/17\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.8.90[0m \u001b[32m 7/17\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/17\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.8.93[0m \u001b[32m 8/17\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.8.93:━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/17\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.8.93━\u001b[0m \u001b[32m 8/17\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu120m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/17\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu12 12.8.90[0m \u001b[32m 9/17\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-cupti-cu12-12.8.90:━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/17\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu12-12.8.90━\u001b[0m \u001b[32m 9/17\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cublas-cu12[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/17\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.8.4.1━━\u001b[0m \u001b[32m10/17\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cublas-cu12-12.8.4.1:m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/17\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1━━━━\u001b[0m \u001b[32m10/17\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusparse-cu12[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/17\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.5.8.93[0m \u001b[32m11/17\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.5.8.93:━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/17\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93━\u001b[0m \u001b[32m11/17\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cudnn-cu12[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m12/17\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cudnn-cu12 9.10.2.21━━\u001b[0m \u001b[32m12/17\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cudnn-cu12-9.10.2.21:m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m12/17\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21━━━━\u001b[0m \u001b[32m12/17\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusolver-cu1291m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m13/17\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.7.3.90[0m \u001b[32m13/17\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m13/17\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90━\u001b[0m \u001b[32m13/17\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K  Attempting uninstall: torch━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m14/17\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Found existing installation: torch 2.9.1[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m15/17\u001b[0m [torch]olver-cu12]\n",
      "\u001b[2K    Uninstalling torch-2.9.1:━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m15/17\u001b[0m [torch]\n",
      "\u001b[2K      Successfully uninstalled torch-2.9.1━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m15/17\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/17\u001b[0m [torchvision]\u001b[0m [torchvision]\n",
      "\u001b[1A\u001b[2KSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 pillow-12.0.0 sympy-1.13.1 torch-2.5.0 torchvision-0.20.0 triton-3.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting setuptools<71.0.0\n",
      "  Downloading setuptools-70.3.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from scikit-learn) (2.3.5)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Downloading scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading setuptools-70.3.0-py3-none-any.whl (931 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m931.1/931.1 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, setuptools, scipy, joblib, scikit-learn\n",
      "\u001b[2K  Attempting uninstall: setuptools\n",
      "\u001b[2K    Found existing installation: setuptools 80.9.0\n",
      "\u001b[2K    Uninstalling setuptools-80.9.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/5\u001b[0m [setuptools]\n",
      "\u001b[2K      Successfully uninstalled setuptools-80.9.0━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/5\u001b[0m [setuptools]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [scikit-learn][0m [scikit-learn]\n",
      "\u001b[1A\u001b[2KSuccessfully installed joblib-1.5.2 scikit-learn-1.7.2 scipy-1.16.3 setuptools-70.3.0 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting datasets==3.1.0\n",
      "  Using cached datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting accelerate==1.2.1\n",
      "  Downloading accelerate-1.2.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting hf-transfer==0.1.8\n",
      "  Downloading hf_transfer-0.1.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: filelock in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from datasets==3.1.0) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from datasets==3.1.0) (2.3.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from datasets==3.1.0) (22.0.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets==3.1.0)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from datasets==3.1.0) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from datasets==3.1.0) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from datasets==3.1.0) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from datasets==3.1.0) (3.6.0)\n",
      "Collecting multiprocess<0.70.17 (from datasets==3.1.0)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets==3.1.0)\n",
      "  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from datasets==3.1.0) (3.13.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from datasets==3.1.0) (0.36.0)\n",
      "Requirement already satisfied: packaging in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from datasets==3.1.0) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from datasets==3.1.0) (6.0.3)\n",
      "Requirement already satisfied: psutil in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from accelerate==1.2.1) (7.1.3)\n",
      "Requirement already satisfied: torch>=1.10.0 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from accelerate==1.2.1) (2.5.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from accelerate==1.2.1) (0.7.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from aiohttp->datasets==3.1.0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from aiohttp->datasets==3.1.0) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from aiohttp->datasets==3.1.0) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from aiohttp->datasets==3.1.0) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from aiohttp->datasets==3.1.0) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from aiohttp->datasets==3.1.0) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from aiohttp->datasets==3.1.0) (1.22.0)\n",
      "Requirement already satisfied: idna>=2.0 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets==3.1.0) (3.11)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from aiosignal>=1.4.0->aiohttp->datasets==3.1.0) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from huggingface-hub>=0.23.0->datasets==3.1.0) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from requests>=2.32.2->datasets==3.1.0) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from requests>=2.32.2->datasets==3.1.0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from requests>=2.32.2->datasets==3.1.0) (2025.11.12)\n",
      "Requirement already satisfied: networkx in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from torch>=1.10.0->accelerate==1.2.1) (3.6)\n",
      "Requirement already satisfied: jinja2 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from torch>=1.10.0->accelerate==1.2.1) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from torch>=1.10.0->accelerate==1.2.1) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from torch>=1.10.0->accelerate==1.2.1) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from torch>=1.10.0->accelerate==1.2.1) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from torch>=1.10.0->accelerate==1.2.1) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from torch>=1.10.0->accelerate==1.2.1) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from torch>=1.10.0->accelerate==1.2.1) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from torch>=1.10.0->accelerate==1.2.1) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from torch>=1.10.0->accelerate==1.2.1) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from torch>=1.10.0->accelerate==1.2.1) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from torch>=1.10.0->accelerate==1.2.1) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from torch>=1.10.0->accelerate==1.2.1) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from torch>=1.10.0->accelerate==1.2.1) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from torch>=1.10.0->accelerate==1.2.1) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from torch>=1.10.0->accelerate==1.2.1) (70.3.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from torch>=1.10.0->accelerate==1.2.1) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate==1.2.1) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from jinja2->torch>=1.10.0->accelerate==1.2.1) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from pandas->datasets==3.1.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from pandas->datasets==3.1.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from pandas->datasets==3.1.0) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets==3.1.0) (1.17.0)\n",
      "Using cached datasets-3.1.0-py3-none-any.whl (480 kB)\n",
      "Downloading accelerate-1.2.1-py3-none-any.whl (336 kB)\n",
      "Downloading hf_transfer-0.1.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Installing collected packages: hf-transfer, fsspec, dill, multiprocess, datasets, accelerate\n",
      "\u001b[2K  Attempting uninstall: fsspec\n",
      "\u001b[2K    Found existing installation: fsspec 2025.10.0\n",
      "\u001b[2K    Uninstalling fsspec-2025.10.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/6\u001b[0m [fsspec]\n",
      "\u001b[2K      Successfully uninstalled fsspec-2025.10.0━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/6\u001b[0m [fsspec]\n",
      "\u001b[2K  Attempting uninstall: dill\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/6\u001b[0m [fsspec]\n",
      "\u001b[2K    Found existing installation: dill 0.4.0━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/6\u001b[0m [dill]\n",
      "\u001b[2K    Uninstalling dill-0.4.0:[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/6\u001b[0m [dill]\n",
      "\u001b[2K      Successfully uninstalled dill-0.4.0━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/6\u001b[0m [dill]\n",
      "\u001b[2K  Attempting uninstall: multiprocess[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/6\u001b[0m [dill]\n",
      "\u001b[2K    Found existing installation: multiprocess 0.70.18━━━━━━━━━\u001b[0m \u001b[32m2/6\u001b[0m [dill]\n",
      "\u001b[2K    Uninstalling multiprocess-0.70.18:\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/6\u001b[0m [multiprocess]\n",
      "\u001b[2K      Successfully uninstalled multiprocess-0.70.18━━━━━━━━━━━\u001b[0m \u001b[32m3/6\u001b[0m [multiprocess]\n",
      "\u001b[2K  Attempting uninstall: datasets\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/6\u001b[0m [multiprocess]\n",
      "\u001b[2K    Found existing installation: datasets 4.4.1━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/6\u001b[0m [multiprocess]\n",
      "\u001b[2K    Uninstalling datasets-4.4.1:━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m4/6\u001b[0m [datasets]\n",
      "\u001b[2K      Successfully uninstalled datasets-4.4.1[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m4/6\u001b[0m [datasets]\n",
      "\u001b[2K  Attempting uninstall: accelerate\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m4/6\u001b[0m [datasets]\n",
      "\u001b[2K    Found existing installation: accelerate 1.12.0━━━━━━━━━━━━\u001b[0m \u001b[32m4/6\u001b[0m [datasets]\n",
      "\u001b[2K    Uninstalling accelerate-1.12.0:━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m5/6\u001b[0m [accelerate]\n",
      "\u001b[2K      Successfully uninstalled accelerate-1.12.0[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m5/6\u001b[0m [accelerate]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6/6\u001b[0m [accelerate]6\u001b[0m [accelerate]\n",
      "\u001b[1A\u001b[2KSuccessfully installed accelerate-1.2.1 datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 hf-transfer-0.1.8 multiprocess-0.70.16\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting git+https://github.com/huggingface/transformers.git@6e0515e99c39444caae39472ee1b2fd76ece32f1\n",
      "  Cloning https://github.com/huggingface/transformers.git (to revision 6e0515e99c39444caae39472ee1b2fd76ece32f1) to /tmp/pip-req-build-9s3eemnq\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-9s3eemnq\n",
      "  Running command git rev-parse -q --verify 'sha^6e0515e99c39444caae39472ee1b2fd76ece32f1'\n",
      "  Running command git fetch -q https://github.com/huggingface/transformers.git 6e0515e99c39444caae39472ee1b2fd76ece32f1\n",
      "  Running command git checkout -q 6e0515e99c39444caae39472ee1b2fd76ece32f1\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit 6e0515e99c39444caae39472ee1b2fd76ece32f1\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from transformers==4.48.0.dev0) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from transformers==4.48.0.dev0) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from transformers==4.48.0.dev0) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from transformers==4.48.0.dev0) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from transformers==4.48.0.dev0) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from transformers==4.48.0.dev0) (2025.11.3)\n",
      "Requirement already satisfied: requests in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from transformers==4.48.0.dev0) (2.32.5)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers==4.48.0.dev0)\n",
      "  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from transformers==4.48.0.dev0) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from transformers==4.48.0.dev0) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48.0.dev0) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48.0.dev0) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48.0.dev0) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from requests->transformers==4.48.0.dev0) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from requests->transformers==4.48.0.dev0) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from requests->transformers==4.48.0.dev0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages (from requests->transformers==4.48.0.dev0) (2025.11.12)\n",
      "Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.48.0.dev0-py3-none-any.whl size=10328690 sha256=2521c141b3c85e2847cf8c516ed87a40ca5ffb14e020a6548197a019a6e82836\n",
      "  Stored in directory: /home/anikrish/.cache/pip/wheels/56/b0/57/02e8f429332137a384d10f98dd94ccae7af86cff127ecba480\n",
      "Successfully built transformers\n",
      "Installing collected packages: tokenizers, transformers\n",
      "\u001b[2K  Attempting uninstall: tokenizers\n",
      "\u001b[2K    Found existing installation: tokenizers 0.22.1\n",
      "\u001b[2K    Uninstalling tokenizers-0.22.1:\n",
      "\u001b[2K      Successfully uninstalled tokenizers-0.22.1\n",
      "\u001b[2K  Attempting uninstall: transformers━━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [tokenizers]\n",
      "\u001b[2K    Found existing installation: transformers 4.57.32m0/2\u001b[0m [tokenizers]\n",
      "\u001b[2K    Uninstalling transformers-4.57.3:╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/2\u001b[0m [transformers]\n",
      "\u001b[2K      Successfully uninstalled transformers-4.57.3━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/2\u001b[0m [transformers]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [transformers][0m [transformers]\n",
      "\u001b[1A\u001b[2KSuccessfully installed tokenizers-0.21.4 transformers-4.48.0.dev0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install \"torch==2.5.0\" \"torchvision==0.20.0\"\n",
    "%pip install \"setuptools<71.0.0\" scikit-learn\n",
    "\n",
    "%pip install  --upgrade \\\n",
    "  \"datasets==3.1.0\" \\\n",
    "  \"accelerate==1.2.1\" \\\n",
    "  \"hf-transfer==0.1.8\"\n",
    "\n",
    "%pip install \"git+https://github.com/huggingface/transformers.git@6e0515e99c39444caae39472ee1b2fd76ece32f1\" --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "608909ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Generating train split: 100%|██████████| 14048/14048 [00:00<00:00, 139075.55 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': ['Which City in San Diego County is considered a great place to live and raise a family?',\n",
       "  'What are the FAANG companies?'],\n",
       " 'rating': [0.2, 0.2]}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets.arrow_dataset import Dataset\n",
    "from datasets.dataset_dict import DatasetDict, IterableDatasetDict\n",
    "from datasets.iterable_dataset import IterableDataset\n",
    "\n",
    "# Dataset id from huggingface.co/dataset\n",
    "dataset_id = \"wesley7137/question_complexity_classification\"\n",
    "\n",
    "# Load raw dataset\n",
    "train_dataset = load_dataset(dataset_id, split='train')\n",
    "\n",
    "split_dataset = train_dataset.train_test_split(test_size=0.1)\n",
    "split_dataset['train'][5:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97181c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 12643/12643 [00:01<00:00, 10673.27 examples/s]\n",
      "Map: 100%|██████████| 1405/1405 [00:00<00:00, 8858.95 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 12643/12643 [00:00<00:00, 1273348.19 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1405/1405 [00:00<00:00, 269492.71 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# # 1. Define the bucketing logic clearly\n",
    "# def get_bucket(example):\n",
    "#     rating = example['rating']\n",
    "    \n",
    "#     # Handle None/Null values if they exist (assign to default or filter later)\n",
    "#     if rating is None:\n",
    "#         return {\"labels\": 0} # Defaulting to Easy, or you can filter these rows out first\n",
    "        \n",
    "#     if rating <= 0.3:\n",
    "#         label = 0\n",
    "#     elif rating <= 0.6:\n",
    "#         label = 1\n",
    "#     else:\n",
    "#         label = 2\n",
    "    \n",
    "#     return {\"labels\": label}\n",
    "\n",
    "# # 2. Apply it using .map()\n",
    "# # This creates the new \"labels\" column efficiently\n",
    "# split_dataset = split_dataset.map(get_bucket)\n",
    "\n",
    "# # 3. (Optional) Remove the old 'rating' column to clean up\n",
    "# split_dataset = split_dataset.remove_columns([\"rating\"])\n",
    "\n",
    "# # Now save\n",
    "# split_dataset.save_to_disk('question_complexity_classification_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c653e507",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Casting the dataset: 100%|██████████| 12643/12643 [00:00<00:00, 16219.28 examples/s]\n",
      "Casting the dataset: 100%|██████████| 1405/1405 [00:00<00:00, 16297.50 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'How would you build me a plane out of duct tape? You can leverage other materials, but the exterior of both the fuselage and the wings must be duct tape.', 'labels': 0.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Regression Approach\n",
    "from datasets import Value\n",
    "\n",
    "# 1. Rename 'rating' (the decimal) to 'labels'\n",
    "split_dataset = split_dataset.rename_column(\"rating\", \"labels\")\n",
    "\n",
    "split_dataset = split_dataset.filter(lambda x: x['labels'] is not None)\n",
    "# 2. Ensure it is a Float (Decimal number)\n",
    "# This converts the column type to ensure regression works\n",
    "split_dataset = split_dataset.cast_column(\"labels\", Value(\"float32\"))\n",
    "\n",
    "# Verify it looks correct (should see decimals like 0.3, 0.7)\n",
    "print(split_dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d833b4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split_dataset = DatasetDict.load_from_disk('question_complexity_classification_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a8429a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
      "0it [00:00, ?it/s]\n",
      "Map: 100%|██████████| 12643/12643 [00:06<00:00, 2081.05 examples/s]\n",
      "Map: 100%|██████████| 1405/1405 [00:00<00:00, 3368.14 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Model id to load the tokenizer\n",
    "model_id = \"answerdotai/ModernBERT-base\"\n",
    "\n",
    "# Load Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# Tokenize helper function\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['question'], truncation=True,padding=True)\n",
    "\n",
    "tokenized_dataset = split_dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3375c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': Value(dtype='string', id=None), 'labels': Value(dtype='float32', id=None), 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_dataset[\"train\"].features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3d949e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# # Model id to load the tokenizer\n",
    "# model_id = \"answerdotai/ModernBERT-base\"\n",
    "\n",
    "# # Prepare model labels - useful for inference\n",
    "# labels = [0, 1, 2]  # 0 - easy, 1 - medium, 2 - hard\n",
    "# num_labels = len(labels)\n",
    "# label2id, id2label = dict(), dict()\n",
    "# for i, label in enumerate(labels):\n",
    "#     label2id[label] = str(i)\n",
    "#     id2label[str(i)] = label\n",
    "\n",
    "# # Download the model from huggingface.co/models\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#     model_id, num_labels=num_labels, label2id=label2id, id2label=id2label,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "528cef92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_id = \"answerdotai/ModernBERT-base\"\n",
    "\n",
    "# Download the model for REGRESSION\n",
    "# num_labels=1 automatically triggers Regression (MSE Loss)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_id, \n",
    "    num_labels=1 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "540537e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('my_model/tokenizer_config.json',\n",
       " 'my_model/special_tokens_map.json',\n",
       " 'my_model/tokenizer.json')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"my_model/\")\n",
    "tokenizer.save_pretrained(\"my_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152fc54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 12643/12643 [00:00<00:00, 209293.90 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1405/1405 [00:00<00:00, 167819.94 examples/s]\n"
     ]
    }
   ],
   "source": [
    "#tokenized_dataset.save_to_disk(\"tokenized_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05c90f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 12643/12643 [00:00<00:00, 241282.50 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1405/1405 [00:00<00:00, 135123.29 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset.save_to_disk(\"tokenized_dataset_regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddade7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Check the first item\n",
    "print(tokenized_dataset[\"train\"][10][\"labels\"]) \n",
    "# Output MUST be an integer like 0, 1, or 2. \n",
    "# If it is 0.15, the fix didn't work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1debecc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0.20000000298023224: 2028, 0.6000000238418579: 1792, 0.30000001192092896: 1685, 0.4000000059604645: 1641, 0.699999988079071: 1639, 0.800000011920929: 1415, 0.5: 1392, 0.8999999761581421: 431, None: 325, 0.05000000074505806: 66, 0.8500000238418579: 39, 0.10000000149011612: 33, 0.75: 32, 0.25: 32, 0.44999998807907104: 19, 0.6499999761581421: 14, 0.550000011920929: 12, 0.3499999940395355: 11, 0.949999988079071: 8, 0.0: 5, 0.15000000596046448: 5, 0.029999999329447746: 4, 0.9700000286102295: 2, 0.41999998688697815: 2, 0.009999999776482582: 2, 0.3199999928474426: 2, 0.6700000166893005: 1, 0.8799999952316284: 1, 0.5600000023841858: 1, 0.4300000071525574: 1, 0.9800000190734863: 1, 0.7599999904632568: 1, 0.0010000000474974513: 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from datasets import load_from_disk\n",
    "tokenized_dataset = load_from_disk(\"tokenized_dataset_regression\")\n",
    "print(Counter(tokenized_dataset['train']['labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea59653e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running prediction on test set...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# 1. Get predictions from the trainer\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRunning prediction on test set...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m predictions_output = \u001b[43mtrainer\u001b[49m.predict(tokenized_dataset[\u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# 2. Convert raw logits to class IDs (0, 1, 2)\u001b[39;00m\n\u001b[32m     11\u001b[39m y_preds = np.argmax(predictions_output.predictions, axis=\u001b[32m1\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Get predictions from the trainer\n",
    "print(\"Running prediction on test set...\")\n",
    "predictions_output = trainer.predict(tokenized_dataset[\"test\"])\n",
    "\n",
    "# 2. Convert raw logits to class IDs (0, 1, 2)\n",
    "y_preds = np.argmax(predictions_output.predictions, axis=1)\n",
    "y_true = predictions_output.label_ids\n",
    "\n",
    "# 3. Create the Matrix\n",
    "cm = confusion_matrix(y_true, y_preds)\n",
    "\n",
    "# 4. Display nicely\n",
    "labels = [\"Easy (0)\", \"Medium (1)\", \"Hard (2)\"]\n",
    "df_cm = pd.DataFrame(cm, index=[f\"True {l}\" for l in labels], \n",
    "                         columns=[f\"Pred {l}\" for l in labels])\n",
    "print(\"\\n--- CONFUSION MATRIX ---\")\n",
    "print(df_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10faa44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/cuda/__init__.py:716: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_inductor/compile_worker/__main__.py\", line 7, in <module>\n",
      "    from torch._inductor.async_compile import pre_fork_setup\n",
      "  File \"/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_inductor/async_compile.py\", line 16, in <module>\n",
      "    from torch._dynamo.device_interface import get_registered_device_interfaces\n",
      "  File \"/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_dynamo/__init__.py\", line 39, in <module>\n",
      "    from .polyfills import loader as _  # usort: skip # noqa: F401\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_dynamo/polyfills/loader.py\", line 22, in <module>\n",
      "    POLYFILLED_MODULES: Tuple[\"ModuleType\", ...] = tuple(\n",
      "                                                   ^^^^^^\n",
      "  File \"/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_dynamo/polyfills/loader.py\", line 23, in <genexpr>\n",
      "    importlib.import_module(f\".{submodule}\", package=polyfills.__name__)\n",
      "  File \"/usr/lib64/python3.12/importlib/__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_dynamo/polyfills/builtins.py\", line 23, in <module>\n",
      "    @substitute_in_graph(builtins.all, can_constant_fold_through=True)\n",
      "     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_dynamo/decorators.py\", line 312, in wrapper\n",
      "    rule_map: Dict[Any, Type[VariableTracker]] = get_torch_obj_rule_map()\n",
      "                                                 ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_dynamo/trace_rules.py\", line 2860, in get_torch_obj_rule_map\n",
      "    obj = load_object(k)\n",
      "          ^^^^^^^^^^^^^^\n",
      "  File \"/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_dynamo/trace_rules.py\", line 2892, in load_object\n",
      "    val = unwrap_if_wrapper(val)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_dynamo/utils.py\", line 683, in unwrap_if_wrapper\n",
      "    return unwrap_with_attr_name_if_wrapper(fn)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_dynamo/utils.py\", line 689, in unwrap_with_attr_name_if_wrapper\n",
      "    if is_function(fn) and inspect.getattr_static(fn, \"_torchdynamo_inline\", False):\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib64/python3.12/inspect.py\", line 1864, in getattr_static\n",
      "    instance_result = _check_instance(obj, attr)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib64/python3.12/inspect.py\", line 1803, in _check_instance\n",
      "    return dict.get(instance_dict, attr, _sentinel)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m classifier = pipeline(\u001b[33m\"\u001b[39m\u001b[33mtext-classification\u001b[39m\u001b[33m\"\u001b[39m, model=model_path, tokenizer=\u001b[33m\"\u001b[39m\u001b[33mmy_model/\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Test it\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat is the square root of 144?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/transformers/pipelines/text_classification.py:159\u001b[39m, in \u001b[36mTextClassificationPipeline.__call__\u001b[39m\u001b[34m(self, inputs, **kwargs)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    125\u001b[39m \u001b[33;03mClassify the text(s) given as inputs.\u001b[39;00m\n\u001b[32m    126\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    156\u001b[39m \u001b[33;03m    If `top_k` is used, one such dictionary is returned per label.\u001b[39;00m\n\u001b[32m    157\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    158\u001b[39m inputs = (inputs,)\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m result = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[38;5;66;03m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001b[39;00m\n\u001b[32m    161\u001b[39m _legacy = \u001b[33m\"\u001b[39m\u001b[33mtop_k\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/transformers/pipelines/base.py:1301\u001b[39m, in \u001b[36mPipeline.__call__\u001b[39m\u001b[34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[39m\n\u001b[32m   1293\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[32m   1294\u001b[39m         \u001b[38;5;28miter\u001b[39m(\n\u001b[32m   1295\u001b[39m             \u001b[38;5;28mself\u001b[39m.get_iterator(\n\u001b[32m   (...)\u001b[39m\u001b[32m   1298\u001b[39m         )\n\u001b[32m   1299\u001b[39m     )\n\u001b[32m   1300\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1301\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/transformers/pipelines/base.py:1308\u001b[39m, in \u001b[36mPipeline.run_single\u001b[39m\u001b[34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[39m\n\u001b[32m   1306\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[32m   1307\u001b[39m     model_inputs = \u001b[38;5;28mself\u001b[39m.preprocess(inputs, **preprocess_params)\n\u001b[32m-> \u001b[39m\u001b[32m1308\u001b[39m     model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1309\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.postprocess(model_outputs, **postprocess_params)\n\u001b[32m   1310\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/transformers/pipelines/base.py:1208\u001b[39m, in \u001b[36mPipeline.forward\u001b[39m\u001b[34m(self, model_inputs, **forward_params)\u001b[39m\n\u001b[32m   1206\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[32m   1207\u001b[39m         model_inputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_inputs, device=\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m-> \u001b[39m\u001b[32m1208\u001b[39m         model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1209\u001b[39m         model_outputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_outputs, device=torch.device(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   1210\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/transformers/pipelines/text_classification.py:190\u001b[39m, in \u001b[36mTextClassificationPipeline._forward\u001b[39m\u001b[34m(self, model_inputs)\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inspect.signature(model_forward).parameters.keys():\n\u001b[32m    189\u001b[39m     model_inputs[\u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/transformers/models/modernbert/modeling_modernbert.py:1160\u001b[39m, in \u001b[36mModernBertForSequenceClassification.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, sliding_window_mask, position_ids, labels, indices, cu_seqlens, max_seqlen, batch_size, seq_len, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[39m\n\u001b[32m   1157\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m   1158\u001b[39m \u001b[38;5;28mself\u001b[39m._maybe_set_compile()\n\u001b[32m-> \u001b[39m\u001b[32m1160\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m    \u001b[49m\u001b[43msliding_window_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43msliding_window_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcu_seqlens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcu_seqlens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_seqlen\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_seqlen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1174\u001b[39m last_hidden_state = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1176\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.classifier_pooling == \u001b[33m\"\u001b[39m\u001b[33mcls\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/transformers/models/modernbert/modeling_modernbert.py:895\u001b[39m, in \u001b[36mModernBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, sliding_window_mask, position_ids, indices, cu_seqlens, max_seqlen, batch_size, seq_len, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    889\u001b[39m         position_ids = torch.arange(seq_len, device=input_ids.device).unsqueeze(\u001b[32m0\u001b[39m)\n\u001b[32m    891\u001b[39m     attention_mask, sliding_window_mask = \u001b[38;5;28mself\u001b[39m._update_attention_mask(\n\u001b[32m    892\u001b[39m         attention_mask, output_attentions=output_attentions\n\u001b[32m    893\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m895\u001b[39m hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    897\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m encoder_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n\u001b[32m    898\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/transformers/models/modernbert/modeling_modernbert.py:210\u001b[39m, in \u001b[36mModernBertEmbeddings.forward\u001b[39m\u001b[34m(self, input_ids, position_ids)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids: torch.LongTensor, position_ids: Optional[torch.LongTensor] = \u001b[38;5;28;01mNone\u001b[39;00m) -> torch.Tensor:\n\u001b[32m    209\u001b[39m     hidden_states = (\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompiled_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    211\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.reference_compile\n\u001b[32m    212\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.drop(\u001b[38;5;28mself\u001b[39m.norm(\u001b[38;5;28mself\u001b[39m.tok_embeddings(input_ids)))\n\u001b[32m    213\u001b[39m     )\n\u001b[32m    214\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_dynamo/eval_frame.py:465\u001b[39m, in \u001b[36m_TorchDynamoContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    460\u001b[39m saved_dynamic_layer_stack_depth = (\n\u001b[32m    461\u001b[39m     torch._C._functorch.get_dynamic_layer_stack_depth()\n\u001b[32m    462\u001b[39m )\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m465\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    467\u001b[39m     \u001b[38;5;66;03m# Restore the dynamic layer stack depth if necessary.\u001b[39;00m\n\u001b[32m    468\u001b[39m     torch._C._functorch.pop_dynamic_layer_stack_and_undo_to_depth(\n\u001b[32m    469\u001b[39m         saved_dynamic_layer_stack_depth\n\u001b[32m    470\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_dynamo/convert_frame.py:1269\u001b[39m, in \u001b[36mCatchErrorsWrapper.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, frame_state)\u001b[39m\n\u001b[32m   1263\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m hijacked_callback(\n\u001b[32m   1264\u001b[39m                 frame, cache_entry, \u001b[38;5;28mself\u001b[39m.hooks, frame_state\n\u001b[32m   1265\u001b[39m             )\n\u001b[32m   1267\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m compile_lock, _disable_current_modes():\n\u001b[32m   1268\u001b[39m     \u001b[38;5;66;03m# skip=1: skip this frame\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1269\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_torchdynamo_orig_callable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1270\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   1271\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_dynamo/convert_frame.py:1064\u001b[39m, in \u001b[36mConvertFrame.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, hooks, frame_state, skip)\u001b[39m\n\u001b[32m   1062\u001b[39m counters[\u001b[33m\"\u001b[39m\u001b[33mframes\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtotal\u001b[39m\u001b[33m\"\u001b[39m] += \u001b[32m1\u001b[39m\n\u001b[32m   1063\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1064\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inner_convert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1065\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   1066\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1067\u001b[39m     counters[\u001b[33m\"\u001b[39m\u001b[33mframes\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mok\u001b[39m\u001b[33m\"\u001b[39m] += \u001b[32m1\u001b[39m\n\u001b[32m   1068\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_dynamo/convert_frame.py:526\u001b[39m, in \u001b[36mConvertFrameAssert.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, hooks, frame_state, skip)\u001b[39m\n\u001b[32m    510\u001b[39m compile_id = CompileId(frame_id, frame_compile_id)\n\u001b[32m    512\u001b[39m signpost_event(\n\u001b[32m    513\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdynamo\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    514\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m_convert_frame_assert._compile\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    523\u001b[39m     },\n\u001b[32m    524\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_globals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_locals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_builtins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_torchdynamo_orig_callable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_one_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_export\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_export_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    536\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    538\u001b[39m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    539\u001b[39m \u001b[43m    \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    540\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompile_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompile_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    541\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    542\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_dynamo/convert_frame.py:924\u001b[39m, in \u001b[36m_compile\u001b[39m\u001b[34m(code, globals, locals, builtins, compiler_fn, one_graph, export, export_constraints, hooks, cache_entry, cache_size, frame, frame_state, compile_id, skip)\u001b[39m\n\u001b[32m    922\u001b[39m guarded_code = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    923\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m924\u001b[39m     guarded_code = \u001b[43mcompile_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    925\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m guarded_code\n\u001b[32m    926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_dynamo/convert_frame.py:666\u001b[39m, in \u001b[36m_compile.<locals>.compile_inner\u001b[39m\u001b[34m(code, one_graph, hooks, transform)\u001b[39m\n\u001b[32m    664\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\u001b[33m\"\u001b[39m\u001b[33m_compile.compile_inner\u001b[39m\u001b[33m\"\u001b[39m, phase_name=\u001b[33m\"\u001b[39m\u001b[33mentire_frame_compile\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    665\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m CompileTimeInstructionCounter.record():\n\u001b[32m--> \u001b[39m\u001b[32m666\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_utils_internal.py:87\u001b[39m, in \u001b[36mcompile_time_strobelight_meta.<locals>.compile_time_strobelight_meta_inner.<locals>.wrapper_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     84\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mskip\u001b[39m\u001b[33m\"\u001b[39m] = kwargs[\u001b[33m\"\u001b[39m\u001b[33mskip\u001b[39m\u001b[33m\"\u001b[39m] + \u001b[32m1\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m StrobelightCompileTimeProfiler.enabled:\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m StrobelightCompileTimeProfiler.profile_compile_time(\n\u001b[32m     90\u001b[39m     function, phase_name, *args, **kwargs\n\u001b[32m     91\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_dynamo/convert_frame.py:699\u001b[39m, in \u001b[36m_compile.<locals>._compile_inner\u001b[39m\u001b[34m(code, one_graph, hooks, transform)\u001b[39m\n\u001b[32m    697\u001b[39m CompileContext.get().attempt = attempt\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m699\u001b[39m     out_code = \u001b[43mtransform_code_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    700\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    701\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exc.RestartAnalysis \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_dynamo/bytecode_transformation.py:1322\u001b[39m, in \u001b[36mtransform_code_object\u001b[39m\u001b[34m(code, transformations, safe)\u001b[39m\n\u001b[32m   1319\u001b[39m instructions = cleaned_instructions(code, safe)\n\u001b[32m   1320\u001b[39m propagate_line_nums(instructions)\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m \u001b[43mtransformations\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m clean_and_assemble_instructions(instructions, keys, code_options)[\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_dynamo/convert_frame.py:219\u001b[39m, in \u001b[36mpreserve_global_state.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    215\u001b[39m exit_stack.enter_context(\n\u001b[32m    216\u001b[39m     torch.fx._symbolic_trace._maybe_revert_all_patches()\n\u001b[32m    217\u001b[39m )\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    221\u001b[39m     cleanup.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_dynamo/convert_frame.py:634\u001b[39m, in \u001b[36m_compile.<locals>.transform\u001b[39m\u001b[34m(instructions, code_options)\u001b[39m\n\u001b[32m    632\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    633\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m tracing(tracer.output.tracing_context), tracer.set_current_tx():\n\u001b[32m--> \u001b[39m\u001b[32m634\u001b[39m         \u001b[43mtracer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exc.UnspecializeRestartAnalysis:\n\u001b[32m    636\u001b[39m     speculation_log.clear()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2796\u001b[39m, in \u001b[36mInstructionTranslator.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2795\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m2796\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:983\u001b[39m, in \u001b[36mInstructionTranslatorBase.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    981\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    982\u001b[39m     \u001b[38;5;28mself\u001b[39m.output.push_tx(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m983\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    984\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    985\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m BackendCompilerFailed:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:895\u001b[39m, in \u001b[36mInstructionTranslatorBase.step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    892\u001b[39m \u001b[38;5;28mself\u001b[39m.update_block_stack(inst)\n\u001b[32m    894\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m895\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdispatch_table\u001b[49m\u001b[43m[\u001b[49m\u001b[43minst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopcode\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    896\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.output.should_exit\n\u001b[32m    897\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exc.ObservedException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2987\u001b[39m, in \u001b[36mInstructionTranslator.RETURN_VALUE\u001b[39m\u001b[34m(self, inst)\u001b[39m\n\u001b[32m   2986\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mRETURN_VALUE\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst):\n\u001b[32m-> \u001b[39m\u001b[32m2987\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_return\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2972\u001b[39m, in \u001b[36mInstructionTranslator._return\u001b[39m\u001b[34m(self, inst)\u001b[39m\n\u001b[32m   2967\u001b[39m _step_logger()(\n\u001b[32m   2968\u001b[39m     logging.INFO,\n\u001b[32m   2969\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtorchdynamo done tracing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.f_code.co_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minst.opname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2970\u001b[39m )\n\u001b[32m   2971\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m triggered compile\u001b[39m\u001b[33m\"\u001b[39m, inst.opname)\n\u001b[32m-> \u001b[39m\u001b[32m2972\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile_subgraph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2973\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2974\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreason\u001b[49m\u001b[43m=\u001b[49m\u001b[43mGraphCompileReason\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2975\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreturn_value\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mframe_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_break\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m   2976\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2977\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2978\u001b[39m return_inst = (\n\u001b[32m   2979\u001b[39m     create_instruction(\u001b[33m\"\u001b[39m\u001b[33mRETURN_VALUE\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2980\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inst.opname == \u001b[33m\"\u001b[39m\u001b[33mRETURN_VALUE\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2981\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m create_instruction(\u001b[33m\"\u001b[39m\u001b[33mRETURN_CONST\u001b[39m\u001b[33m\"\u001b[39m, argval=inst.argval)\n\u001b[32m   2982\u001b[39m )\n\u001b[32m   2983\u001b[39m \u001b[38;5;28mself\u001b[39m.output.add_output_instructions([return_inst])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_dynamo/output_graph.py:1117\u001b[39m, in \u001b[36mOutputGraph.compile_subgraph\u001b[39m\u001b[34m(self, tx, partial_convert, reason)\u001b[39m\n\u001b[32m   1114\u001b[39m append_prefix_insts()\n\u001b[32m   1115\u001b[39m \u001b[38;5;66;03m# optimization to generate better code in a common case\u001b[39;00m\n\u001b[32m   1116\u001b[39m \u001b[38;5;28mself\u001b[39m.add_output_instructions(\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompile_and_call_fx_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mreversed\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstack_values\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1118\u001b[39m     + [create_instruction(\u001b[33m\"\u001b[39m\u001b[33mUNPACK_SEQUENCE\u001b[39m\u001b[33m\"\u001b[39m, arg=\u001b[38;5;28mlen\u001b[39m(stack_values))]\n\u001b[32m   1119\u001b[39m )\n\u001b[32m   1120\u001b[39m \u001b[38;5;66;03m# restore all the live local vars\u001b[39;00m\n\u001b[32m   1121\u001b[39m \u001b[38;5;28mself\u001b[39m.add_output_instructions(\n\u001b[32m   1122\u001b[39m     [PyCodegen(tx).create_store(var) \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(restore_vars)]\n\u001b[32m   1123\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_dynamo/output_graph.py:1369\u001b[39m, in \u001b[36mOutputGraph.compile_and_call_fx_graph\u001b[39m\u001b[34m(self, tx, rv, root)\u001b[39m\n\u001b[32m   1366\u001b[39m     \u001b[38;5;28mself\u001b[39m.tracing_context.fake_mode = backend_fake_mode\n\u001b[32m   1368\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.restore_global_state():\n\u001b[32m-> \u001b[39m\u001b[32m1369\u001b[39m     compiled_fn = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_user_compiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1371\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_lazy_graph_module\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _LazyGraphModule\n\u001b[32m   1373\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(compiled_fn, _LazyGraphModule) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1374\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(compiled_fn, \u001b[33m\"\u001b[39m\u001b[33m__self__\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m), _LazyGraphModule)\n\u001b[32m   1375\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m compiled_fn.\u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m_lazy_forward\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1379\u001b[39m     \u001b[38;5;66;03m# this is a _LazyGraphModule. This makes it easier for dynamo to\u001b[39;00m\n\u001b[32m   1380\u001b[39m     \u001b[38;5;66;03m# optimize a _LazyGraphModule.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_dynamo/output_graph.py:1416\u001b[39m, in \u001b[36mOutputGraph.call_user_compiler\u001b[39m\u001b[34m(self, gm)\u001b[39m\n\u001b[32m   1412\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_user_compiler\u001b[39m(\u001b[38;5;28mself\u001b[39m, gm: fx.GraphModule) -> CompiledFn:\n\u001b[32m   1413\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\n\u001b[32m   1414\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mOutputGraph.call_user_compiler\u001b[39m\u001b[33m\"\u001b[39m, phase_name=\u001b[33m\"\u001b[39m\u001b[33mbackend_compile\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1415\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1416\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_user_compiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_dynamo/output_graph.py:1446\u001b[39m, in \u001b[36mOutputGraph._call_user_compiler\u001b[39m\u001b[34m(self, gm)\u001b[39m\n\u001b[32m   1444\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config.verify_correctness:\n\u001b[32m   1445\u001b[39m     compiler_fn = WrapperBackend(compiler_fn)\n\u001b[32m-> \u001b[39m\u001b[32m1446\u001b[39m compiled_fn = \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1447\u001b[39m _step_logger()(logging.INFO, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdone compiler function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1448\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(compiled_fn), \u001b[33m\"\u001b[39m\u001b[33mcompiler_fn did not return callable\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py:129\u001b[39m, in \u001b[36mWrapBackendDebug.__call__\u001b[39m\u001b[34m(self, gm, example_inputs, **kwargs)\u001b[39m\n\u001b[32m    127\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     compiled_gm = \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m compiled_gm\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/__init__.py:2235\u001b[39m, in \u001b[36m_TorchCompileInductorWrapper.__call__\u001b[39m\u001b[34m(self, model_, inputs_)\u001b[39m\n\u001b[32m   2232\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_, inputs_):\n\u001b[32m   2233\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_inductor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompile_fx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compile_fx\n\u001b[32m-> \u001b[39m\u001b[32m2235\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompile_fx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_patches\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_inductor/compile_fx.py:1521\u001b[39m, in \u001b[36mcompile_fx\u001b[39m\u001b[34m(model_, example_inputs_, inner_compile, config_patches, decompositions)\u001b[39m\n\u001b[32m   1514\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m inference_compiler(unlifted_gm, example_inputs_)\n\u001b[32m   1516\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m V.set_fake_mode(fake_mode), torch._guards.tracing(\n\u001b[32m   1517\u001b[39m     tracing_context\n\u001b[32m   1518\u001b[39m ), compiled_autograd.disable(), functorch_config.patch(\n\u001b[32m   1519\u001b[39m     unlift_effect_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1520\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1521\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43maot_autograd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfw_compiler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfw_compiler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1523\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbw_compiler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbw_compiler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1524\u001b[39m \u001b[43m        \u001b[49m\u001b[43minference_compiler\u001b[49m\u001b[43m=\u001b[49m\u001b[43minference_compiler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1525\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecompositions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecompositions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1526\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpartition_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartition_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1527\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_inference_input_mutations\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1528\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcudagraphs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcudagraphs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1529\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs_\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_dynamo/backends/common.py:72\u001b[39m, in \u001b[36mAotAutograd.__call__\u001b[39m\u001b[34m(self, gm, example_inputs, **kwargs)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     70\u001b[39m     \u001b[38;5;66;03m# NB: NOT cloned!\u001b[39;00m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m enable_aot_logging(), patch_config:\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m         cg = \u001b[43maot_module_simplified\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m         counters[\u001b[33m\"\u001b[39m\u001b[33maot_autograd\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mok\u001b[39m\u001b[33m\"\u001b[39m] += \u001b[32m1\u001b[39m\n\u001b[32m     74\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m disable(cg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_functorch/aot_autograd.py:1071\u001b[39m, in \u001b[36maot_module_simplified\u001b[39m\u001b[34m(mod, args, fw_compiler, bw_compiler, partition_fn, decompositions, keep_inference_input_mutations, inference_compiler, cudagraphs)\u001b[39m\n\u001b[32m   1067\u001b[39m     compiled_fn = AOTAutogradCache.load(\n\u001b[32m   1068\u001b[39m         dispatch_and_compile, mod, fake_flat_args, aot_config, cudagraphs\n\u001b[32m   1069\u001b[39m     )\n\u001b[32m   1070\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1071\u001b[39m     compiled_fn = \u001b[43mdispatch_and_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1073\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mod, torch._dynamo.utils.GmWrapper):\n\u001b[32m   1074\u001b[39m     \u001b[38;5;66;03m# This function is called by the flatten_graph_inputs wrapper, which boxes\u001b[39;00m\n\u001b[32m   1075\u001b[39m     \u001b[38;5;66;03m# the inputs so that they can be freed before the end of this scope.\u001b[39;00m\n\u001b[32m   1076\u001b[39m     \u001b[38;5;66;03m# For overhead reasons, this is not the default wrapper, see comment:\u001b[39;00m\n\u001b[32m   1077\u001b[39m     \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/pull/122535/files#r1560096481\u001b[39;00m\n\u001b[32m   1078\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mboxed_forward\u001b[39m(runtime_args: List[Any]):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_functorch/aot_autograd.py:1056\u001b[39m, in \u001b[36maot_module_simplified.<locals>.dispatch_and_compile\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1054\u001b[39m functional_call = create_functional_call(mod, params_spec, params_len)\n\u001b[32m   1055\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m compiled_autograd.disable():\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m     compiled_fn, _ = \u001b[43mcreate_aot_dispatcher_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunctional_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1058\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfake_flat_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1059\u001b[39m \u001b[43m        \u001b[49m\u001b[43maot_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1060\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfake_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1061\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshape_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1062\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1063\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m compiled_fn\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_functorch/aot_autograd.py:522\u001b[39m, in \u001b[36mcreate_aot_dispatcher_function\u001b[39m\u001b[34m(flat_fn, fake_flat_args, aot_config, fake_mode, shape_env)\u001b[39m\n\u001b[32m    514\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_aot_dispatcher_function\u001b[39m(\n\u001b[32m    515\u001b[39m     flat_fn,\n\u001b[32m    516\u001b[39m     fake_flat_args: FakifiedFlatArgs,\n\u001b[32m   (...)\u001b[39m\u001b[32m    519\u001b[39m     shape_env: Optional[ShapeEnv],\n\u001b[32m    520\u001b[39m ) -> Tuple[Callable, ViewAndMutationMeta]:\n\u001b[32m    521\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\u001b[33m\"\u001b[39m\u001b[33mcreate_aot_dispatcher_function\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m522\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_create_aot_dispatcher_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m            \u001b[49m\u001b[43mflat_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfake_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maot_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfake_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape_env\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_functorch/aot_autograd.py:759\u001b[39m, in \u001b[36m_create_aot_dispatcher_function\u001b[39m\u001b[34m(flat_fn, fake_flat_args, aot_config, fake_mode, shape_env)\u001b[39m\n\u001b[32m    755\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m aot_dispatch_base\n\u001b[32m    757\u001b[39m compiler_fn = choose_dispatcher(needs_autograd, aot_config)\n\u001b[32m--> \u001b[39m\u001b[32m759\u001b[39m compiled_fn, fw_metadata = \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    760\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    761\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_dup_fake_script_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfake_flat_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    762\u001b[39m \u001b[43m    \u001b[49m\u001b[43maot_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    763\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfw_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfw_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    764\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    765\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m compiled_fn, fw_metadata\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:179\u001b[39m, in \u001b[36maot_dispatch_base\u001b[39m\u001b[34m(flat_fn, flat_args, aot_config, fw_metadata)\u001b[39m\n\u001b[32m    172\u001b[39m     tracing_context.fw_metadata = (\n\u001b[32m    173\u001b[39m         fw_metadata\n\u001b[32m    174\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m maybe_subclass_meta \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    175\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m maybe_subclass_meta.fw_metadata\n\u001b[32m    176\u001b[39m     )\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m TracingContext.report_output_strides() \u001b[38;5;28;01mas\u001b[39;00m fwd_output_strides:\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m     compiled_fw = \u001b[43mcompiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfw_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdated_flat_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fakified_out_wrapper.needs_post_compile:\n\u001b[32m    182\u001b[39m     fakified_out_wrapper.set_fwd_output_strides(fwd_output_strides)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_inductor/compile_fx.py:1350\u001b[39m, in \u001b[36mcompile_fx.<locals>.fw_compiler_base\u001b[39m\u001b[34m(model, example_inputs, is_inference)\u001b[39m\n\u001b[32m   1344\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfw_compiler_base\u001b[39m(\n\u001b[32m   1345\u001b[39m     model: torch.fx.GraphModule,\n\u001b[32m   1346\u001b[39m     example_inputs: List[torch.Tensor],\n\u001b[32m   1347\u001b[39m     is_inference: \u001b[38;5;28mbool\u001b[39m,\n\u001b[32m   1348\u001b[39m ):\n\u001b[32m   1349\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m dynamo_utils.dynamo_timed(\u001b[33m\"\u001b[39m\u001b[33mcompile_fx.<locals>.fw_compiler_base\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1350\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_fw_compiler_base\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_inference\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_inductor/compile_fx.py:1421\u001b[39m, in \u001b[36mcompile_fx.<locals>._fw_compiler_base\u001b[39m\u001b[34m(model, example_inputs, is_inference)\u001b[39m\n\u001b[32m   1411\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m orig_output_end_idx <= num_model_outputs\n\u001b[32m   1413\u001b[39m     user_visible_outputs = \u001b[38;5;28mdict\u001b[39m.fromkeys(\n\u001b[32m   1414\u001b[39m         n.name\n\u001b[32m   1415\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m model_outputs[\n\u001b[32m   (...)\u001b[39m\u001b[32m   1418\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(n, torch.fx.Node)\n\u001b[32m   1419\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1421\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1422\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1423\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1424\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstatic_input_idxs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_static_input_idxs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfixed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1425\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcudagraphs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcudagraphs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1426\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgraph_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgraph_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1427\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_inference\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_inference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1428\u001b[39m \u001b[43m    \u001b[49m\u001b[43mboxed_forward_device_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforward_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1429\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser_visible_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_visible_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1430\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_inductor/compile_fx.py:475\u001b[39m, in \u001b[36mcompile_fx_inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    472\u001b[39m stack.enter_context(with_fresh_cache_if_config())\n\u001b[32m    473\u001b[39m stack.enter_context(DebugContext())\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrap_compiler_debug\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_compile_fx_inner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompiler_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minductor\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:85\u001b[39m, in \u001b[36mwrap_compiler_debug.<locals>.debug_wrapper\u001b[39m\u001b[34m(gm, example_inputs, **kwargs)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m config.repro_after \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mdynamo\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33maot\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     83\u001b[39m     \u001b[38;5;66;03m# Call the compiler_fn - which is either aot_autograd or inductor\u001b[39;00m\n\u001b[32m     84\u001b[39m     \u001b[38;5;66;03m# with fake inputs\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     inner_compiled_fn = \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     87\u001b[39m     \u001b[38;5;66;03m# TODO: Failures here are troublesome because no real inputs,\u001b[39;00m\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# need a different serialization strategy\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config.repro_after == \u001b[33m\"\u001b[39m\u001b[33maot\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_inductor/compile_fx.py:661\u001b[39m, in \u001b[36m_compile_fx_inner\u001b[39m\u001b[34m(gm, example_inputs, cudagraphs, static_input_idxs, is_backward, graph_id, cpp_wrapper, aot_mode, is_inference, boxed_forward_device_index, user_visible_outputs, layout_opt, extern_node_serializer)\u001b[39m\n\u001b[32m    654\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    655\u001b[39m             \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, torch.Tensor)\n\u001b[32m    656\u001b[39m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28minput\u001b[39m.device.type == \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    657\u001b[39m             \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m static_input_idxs\n\u001b[32m    658\u001b[39m         ):\n\u001b[32m    659\u001b[39m             \u001b[38;5;28minput\u001b[39m._is_inductor_static = \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m661\u001b[39m     compiled_graph = \u001b[43mFxGraphCache\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    662\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcodegen_and_compile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    663\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    664\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    665\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgraph_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    666\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_to_check\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    667\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfx_graph_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mremote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfx_graph_remote_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    671\u001b[39m     compiled_graph = codegen_and_compile(\n\u001b[32m    672\u001b[39m         gm, example_inputs, inputs_to_check, graph_kwargs  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    673\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_inductor/codecache.py:1298\u001b[39m, in \u001b[36mFxGraphCache.load\u001b[39m\u001b[34m(compile_fx_fn, gm, example_inputs, fx_kwargs, inputs_to_check, local, remote)\u001b[39m\n\u001b[32m   1296\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1297\u001b[39m     FxGraphCache._check_can_cache(gm)\n\u001b[32m-> \u001b[39m\u001b[32m1298\u001b[39m     key, debug_lines = \u001b[43mcompiled_fx_graph_hash\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1299\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfx_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_to_check\u001b[49m\n\u001b[32m   1300\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1301\u001b[39m     cache_info[\u001b[33m\"\u001b[39m\u001b[33mkey\u001b[39m\u001b[33m\"\u001b[39m] = key\n\u001b[32m   1302\u001b[39m     cache_info[\u001b[33m\"\u001b[39m\u001b[33mcomponents\u001b[39m\u001b[33m\"\u001b[39m] = debug_lines\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_inductor/codecache.py:793\u001b[39m, in \u001b[36mcompiled_fx_graph_hash\u001b[39m\u001b[34m(gm, example_inputs, fx_kwargs, inputs_to_check)\u001b[39m\n\u001b[32m    784\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompiled_fx_graph_hash\u001b[39m(\n\u001b[32m    785\u001b[39m     gm: torch.fx.GraphModule,\n\u001b[32m    786\u001b[39m     example_inputs: List[torch.Tensor],\n\u001b[32m    787\u001b[39m     fx_kwargs: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[32m    788\u001b[39m     inputs_to_check: Sequence[\u001b[38;5;28mint\u001b[39m],\n\u001b[32m    789\u001b[39m ) -> Tuple[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m]]:\n\u001b[32m    790\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    791\u001b[39m \u001b[33;03m    Generate a unique hash of the FX graph for caching.\u001b[39;00m\n\u001b[32m    792\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m793\u001b[39m     details = \u001b[43mFxGraphHashDetails\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfx_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_to_check\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    794\u001b[39m     \u001b[38;5;66;03m# The prefix distinguishes among the other kinds of objects we\u001b[39;00m\n\u001b[32m    795\u001b[39m     \u001b[38;5;66;03m# cache in this module.\u001b[39;00m\n\u001b[32m    796\u001b[39m     key = \u001b[33m\"\u001b[39m\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m + FxGraphCachePickler.get_hash(details)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_inductor/codecache.py:771\u001b[39m, in \u001b[36mFxGraphHashDetails.__init__\u001b[39m\u001b[34m(self, gm, example_inputs, fx_kwargs, inputs_to_check)\u001b[39m\n\u001b[32m    764\u001b[39m \u001b[38;5;28mself\u001b[39m.cuda_matmul_settings = (\n\u001b[32m    765\u001b[39m     torch.backends.cuda.matmul.allow_tf32,\n\u001b[32m    766\u001b[39m     torch.backends.cuda.matmul.allow_fp16_reduced_precision_reduction,\n\u001b[32m    767\u001b[39m     torch.backends.cuda.matmul.allow_bf16_reduced_precision_reduction,\n\u001b[32m    768\u001b[39m )\n\u001b[32m    770\u001b[39m \u001b[38;5;66;03m# Also hash on various system info (including the triton compiler version).\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m771\u001b[39m \u001b[38;5;28mself\u001b[39m.torch_version = \u001b[43mtorch_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    772\u001b[39m \u001b[38;5;28mself\u001b[39m.system_info = CacheBase.get_system()\n\u001b[32m    773\u001b[39m \u001b[38;5;28mself\u001b[39m.inductor_config = config.save_config_portable()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_inductor/codecache.py:696\u001b[39m, in \u001b[36mtorch_key\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    693\u001b[39m                     hasher.update(f.read())\n\u001b[32m    694\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m hasher.digest()\n\u001b[32m--> \u001b[39m\u001b[32m696\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_code_hash\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_TORCH_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlibfb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parutil\n\u001b[32m    700\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m parutil.get_file_contents(\u001b[33m\"\u001b[39m\u001b[33mtorch/src_hash.txt\u001b[39m\u001b[33m\"\u001b[39m).rstrip().encode(\u001b[33m\"\u001b[39m\u001b[33mascii\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_inductor/codecache.py:689\u001b[39m, in \u001b[36mtorch_key.<locals>.get_code_hash\u001b[39m\u001b[34m(root)\u001b[39m\n\u001b[32m    687\u001b[39m hasher = hashlib.sha256()\n\u001b[32m    688\u001b[39m hasher.update(torch.__version__.encode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m--> \u001b[39m\u001b[32m689\u001b[39m \u001b[43mbuild_code_hash\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m extra_files:\n\u001b[32m    691\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m os.path.exists(path):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_inductor/codecache.py:665\u001b[39m, in \u001b[36mbuild_code_hash\u001b[39m\u001b[34m(roots, prefix, hasher)\u001b[39m\n\u001b[32m    662\u001b[39m     hasher.update(f.read())\n\u001b[32m    663\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m lib.ispkg:\n\u001b[32m    664\u001b[39m     \u001b[38;5;66;03m# need to also hash submodules\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m665\u001b[39m     \u001b[43mbuild_code_hash\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m.\u001b[49m\u001b[43msubmodule_search_locations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mspec\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasher\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_inductor/codecache.py:665\u001b[39m, in \u001b[36mbuild_code_hash\u001b[39m\u001b[34m(roots, prefix, hasher)\u001b[39m\n\u001b[32m    662\u001b[39m     hasher.update(f.read())\n\u001b[32m    663\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m lib.ispkg:\n\u001b[32m    664\u001b[39m     \u001b[38;5;66;03m# need to also hash submodules\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m665\u001b[39m     \u001b[43mbuild_code_hash\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m.\u001b[49m\u001b[43msubmodule_search_locations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mspec\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasher\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping similar frames: build_code_hash at line 665 (1 times)]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_inductor/codecache.py:665\u001b[39m, in \u001b[36mbuild_code_hash\u001b[39m\u001b[34m(roots, prefix, hasher)\u001b[39m\n\u001b[32m    662\u001b[39m     hasher.update(f.read())\n\u001b[32m    663\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m lib.ispkg:\n\u001b[32m    664\u001b[39m     \u001b[38;5;66;03m# need to also hash submodules\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m665\u001b[39m     \u001b[43mbuild_code_hash\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m.\u001b[49m\u001b[43msubmodule_search_locations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mspec\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasher\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/_inductor/codecache.py:662\u001b[39m, in \u001b[36mbuild_code_hash\u001b[39m\u001b[34m(roots, prefix, hasher)\u001b[39m\n\u001b[32m    660\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(module, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    661\u001b[39m     hasher.update(spec.name.encode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m--> \u001b[39m\u001b[32m662\u001b[39m     hasher.update(\u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    663\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m lib.ispkg:\n\u001b[32m    664\u001b[39m     \u001b[38;5;66;03m# need to also hash submodules\u001b[39;00m\n\u001b[32m    665\u001b[39m     build_code_hash(spec.submodule_search_locations, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, hasher)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Point directly to the best checkpoint\n",
    "model_path = \"ModernBERT-domain-classifier/checkpoint-198\"\n",
    "\n",
    "# Load the classifier\n",
    "classifier = pipeline(\"text-classification\", model=model_path, tokenizer=\"my_model/\")\n",
    "\n",
    "# Test it\n",
    "print(classifier(\"What is the square root of 144?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d624a5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from ModernBERT-domain-classifier/checkpoint-198...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/cuda/__init__.py:716: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running prediction on test set...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='176' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  4/176 02:11 < 2:06:01, 0.02 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# 4. Get Predictions\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRunning prediction on test set...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m predictions_output = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenized_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtest\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# 5. Process Results\u001b[39;00m\n\u001b[32m     36\u001b[39m y_preds = np.argmax(predictions_output.predictions, axis=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/transformers/trainer.py:4144\u001b[39m, in \u001b[36mTrainer.predict\u001b[39m\u001b[34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[39m\n\u001b[32m   4141\u001b[39m start_time = time.time()\n\u001b[32m   4143\u001b[39m eval_loop = \u001b[38;5;28mself\u001b[39m.prediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.use_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.evaluation_loop\n\u001b[32m-> \u001b[39m\u001b[32m4144\u001b[39m output = \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4145\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPrediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\n\u001b[32m   4146\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4147\u001b[39m total_batch_size = \u001b[38;5;28mself\u001b[39m.args.eval_batch_size * \u001b[38;5;28mself\u001b[39m.args.world_size\n\u001b[32m   4148\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_jit_compilation_time\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output.metrics:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/transformers/trainer.py:4260\u001b[39m, in \u001b[36mTrainer.evaluation_loop\u001b[39m\u001b[34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[39m\n\u001b[32m   4257\u001b[39m         batch_size = observed_batch_size\n\u001b[32m   4259\u001b[39m \u001b[38;5;66;03m# Prediction step\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4260\u001b[39m losses, logits, labels = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprediction_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4261\u001b[39m main_input_name = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.model, \u001b[33m\"\u001b[39m\u001b[33mmain_input_name\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   4262\u001b[39m inputs_decode = (\n\u001b[32m   4263\u001b[39m     \u001b[38;5;28mself\u001b[39m._prepare_input(inputs[main_input_name]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33minputs\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args.include_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4264\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/transformers/trainer.py:4476\u001b[39m, in \u001b[36mTrainer.prediction_step\u001b[39m\u001b[34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[39m\n\u001b[32m   4474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_labels \u001b[38;5;129;01mor\u001b[39;00m loss_without_labels:\n\u001b[32m   4475\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compute_loss_context_manager():\n\u001b[32m-> \u001b[39m\u001b[32m4476\u001b[39m         loss, outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   4477\u001b[39m     loss = loss.mean().detach()\n\u001b[32m   4479\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/transformers/trainer.py:3724\u001b[39m, in \u001b[36mTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[39m\n\u001b[32m   3722\u001b[39m         loss_kwargs[\u001b[33m\"\u001b[39m\u001b[33mnum_items_in_batch\u001b[39m\u001b[33m\"\u001b[39m] = num_items_in_batch\n\u001b[32m   3723\u001b[39m     inputs = {**inputs, **loss_kwargs}\n\u001b[32m-> \u001b[39m\u001b[32m3724\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3725\u001b[39m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[32m   3726\u001b[39m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[32m   3727\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.past_index >= \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/transformers/models/modernbert/modeling_modernbert.py:1160\u001b[39m, in \u001b[36mModernBertForSequenceClassification.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, sliding_window_mask, position_ids, labels, indices, cu_seqlens, max_seqlen, batch_size, seq_len, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[39m\n\u001b[32m   1157\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m   1158\u001b[39m \u001b[38;5;28mself\u001b[39m._maybe_set_compile()\n\u001b[32m-> \u001b[39m\u001b[32m1160\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m    \u001b[49m\u001b[43msliding_window_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43msliding_window_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcu_seqlens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcu_seqlens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_seqlen\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_seqlen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1174\u001b[39m last_hidden_state = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1176\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.classifier_pooling == \u001b[33m\"\u001b[39m\u001b[33mcls\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/transformers/models/modernbert/modeling_modernbert.py:913\u001b[39m, in \u001b[36mModernBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, sliding_window_mask, position_ids, indices, cu_seqlens, max_seqlen, batch_size, seq_len, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    902\u001b[39m     layer_outputs = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m    903\u001b[39m         encoder_layer.\u001b[34m__call__\u001b[39m,\n\u001b[32m    904\u001b[39m         hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    910\u001b[39m         output_attentions,\n\u001b[32m    911\u001b[39m     )\n\u001b[32m    912\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m913\u001b[39m     layer_outputs = \u001b[43mencoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    914\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m        \u001b[49m\u001b[43msliding_window_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43msliding_window_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcu_seqlens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcu_seqlens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_seqlen\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_seqlen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    922\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    923\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(layer_outputs) > \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/accounts/cse585f25_class_root/cse585f25_class/anikrish/.venv/lib64/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, DataCollatorWithPadding\n",
    "from datasets import load_from_disk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 1. Load the Best Model (Checkpoint-198)\n",
    "# We load specifically from the checkpoint folder to ensure we test the best version\n",
    "checkpoint_path = \"ModernBERT-domain-classifier/checkpoint-198\"\n",
    "\n",
    "print(f\"Loading model from {checkpoint_path}...\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    checkpoint_path,\n",
    "    num_labels=3,\n",
    "    reference_compile=False # Keep this to avoid the Python.h error\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"my_model/\") # Or the base model name\n",
    "\n",
    "# 2. Load Dataset\n",
    "tokenized_dataset = load_from_disk(\"tokenized_dataset\")\n",
    "\n",
    "# 3. Create a simple Trainer for prediction\n",
    "# We don't need all the training args, just the model and collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "# 4. Get Predictions\n",
    "print(\"Running prediction on test set...\")\n",
    "predictions_output = trainer.predict(tokenized_dataset[\"test\"])\n",
    "\n",
    "# 5. Process Results\n",
    "y_preds = np.argmax(predictions_output.predictions, axis=1)\n",
    "y_true = predictions_output.label_ids\n",
    "\n",
    "# 6. Generate Matrix\n",
    "cm = confusion_matrix(y_true, y_preds)\n",
    "\n",
    "# 7. Display with Pandas\n",
    "labels = [\"Easy (0)\", \"Medium (1)\", \"Hard (2)\"]\n",
    "df_cm = pd.DataFrame(cm, index=[f\"True {l}\" for l in labels], \n",
    "                         columns=[f\"Pred {l}\" for l in labels])\n",
    "\n",
    "print(\"\\n--- CONFUSION MATRIX ---\")\n",
    "print(df_cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
