# Authz-RBAC E2E Profile Values
#
# Demonstrates RBAC-based model routing using simulated user identity
# headers. Different users are routed to different models based on
# role bindings:
#
#   admin        → Qwen 14B (unrestricted, reasoning enabled)
#   premium_user → Qwen 14B (complex) or 7B (simple)
#   free_user    → Qwen 7B only
#   (no role)    → Qwen 7B (default)
#
# Architecture:
#   Client -> Envoy -> ext_proc (semantic router) -> vLLM endpoints
#
# Identity headers (x-authz-user-id, x-authz-user-groups) are injected
# directly in test requests to simulate what an auth backend would set.
# No JWT, Authorino, or any external auth system is required.
#
# Test Users:
#   alice / platform-admins  → admin
#   bob   / premium-tier     → premium_user
#   carol / free-tier        → free_user

replicaCount: 1

image:
  repository: ghcr.io/vllm-project/semantic-router/extproc
  pullPolicy: Never
  tag: "e2e-test"

service:
  type: ClusterIP
  port: 8080

config:
  clear_route_cache: true
  default_model: "Qwen/Qwen2.5-7B-Instruct"

  # --- Authz ---
  # Default identity headers — no custom config needed.
  # The router reads x-authz-user-id and x-authz-user-groups headers.
  authz:
    fail_open: true

  # --- Rate Limiting ---
  # Local limiter: per-user sliding window counters, no external service.
  # Limits are intentionally low for testability:
  #   free-tier       → 3 RPM  (easy to exhaust in e2e tests)
  #   premium-tier    → 10 RPM
  #   platform-admins → 500 RPM
  ratelimit:
    fail_open: false
    providers:
      - type: local-limiter
        rules:
          - name: "free-rpm"
            match:
              group: "free-tier"
            requests_per_unit: 3
            unit: minute
          - name: "premium-rpm"
            match:
              group: "premium-tier"
            requests_per_unit: 10
            unit: minute
          - name: "admin-rpm"
            match:
              group: "platform-admins"
            requests_per_unit: 500
            unit: minute

  # --- Endpoints ---
  # Two vLLM simulator instances: 14B (high capability) and 7B (efficient)
  vllm_endpoints:
    - name: "vllm-14b"
      address: "vllm-14b.default.svc.cluster.local"
      port: 8000
      weight: 1
      type: "vllm"

    - name: "vllm-7b"
      address: "vllm-7b.default.svc.cluster.local"
      port: 8000
      weight: 1
      type: "vllm"

  # --- Model Configuration ---
  model_config:
    "Qwen/Qwen2.5-14B-Instruct":
      preferred_endpoints: ["vllm-14b"]
      param_size: "14b"
      quality_score: 0.90
      description: "Qwen2.5 14B — high-capability model"
      capabilities: ["chat", "code", "reasoning", "math"]
      external_model_ids:
        vllm: "Qwen/Qwen2.5-14B-Instruct"

    "Qwen/Qwen2.5-7B-Instruct":
      preferred_endpoints: ["vllm-7b"]
      param_size: "7b"
      quality_score: 0.70
      description: "Qwen2.5 7B — efficient model"
      capabilities: ["chat", "code"]
      external_model_ids:
        vllm: "Qwen/Qwen2.5-7B-Instruct"

  # --- Classifier ---
  classifier:
    category_model:
      model_id: "models/mom-domain-classifier"
      use_modernbert: false
      threshold: 0.6
      use_cpu: true
      category_mapping_path: "models/mom-domain-classifier/category_mapping.json"
    pii_model:
      model_id: "models/mom-pii-classifier"
      use_modernbert: false
      threshold: 0.7
      use_cpu: true
      pii_mapping_path: "models/mom-pii-classifier/pii_type_mapping.json"

  # --- Prompt Guard (global defaults) ---
  prompt_guard:
    enabled: true
    use_modernbert: false
    model_id: "models/mom-jailbreak-classifier"
    jailbreak_mapping_path: "models/mom-jailbreak-classifier/jailbreak_type_mapping.json"
    threshold: 0.7
    use_cpu: true

  # --- BERT Model for embeddings ---
  bert_model:
    model_id: models/mom-embedding-light
    threshold: 0.6
    use_cpu: true

  # --- Categories ---
  categories:
    - name: code
      description: "Programming, debugging, and software engineering tasks"
    - name: general
      description: "General knowledge, conversation, and miscellaneous topics"

  # --- Keyword Rules ---
  keyword_rules:
    - name: "complex_analysis"
      operator: "OR"
      keywords:
        - "analyze"
        - "reasoning"
        - "think step by step"
        - "explain why"
        - "compare"
        - "evaluate"

    - name: "code_request"
      operator: "OR"
      keywords:
        - "write code"
        - "implement"
        - "function"
        - "algorithm"
        - "debug"
        - "refactor"

  # --- Role Bindings ---
  role_bindings:
    - name: "admin-binding"
      description: "Platform admins — full model access"
      subjects:
        - kind: Group
          name: "platform-admins"
      role: "admin"

    - name: "premium-binding"
      description: "Premium tier users"
      subjects:
        - kind: Group
          name: "premium-tier"
      role: "premium_user"

    - name: "free-binding"
      description: "Free tier users"
      subjects:
        - kind: Group
          name: "free-tier"
      role: "free_user"

  # --- Routing Strategy ---
  strategy: "priority"

  # --- Routing Decisions ---
  decisions:
    # ── Admin: unrestricted, reasoning enabled ──
    - name: "admin_unrestricted"
      description: "Admin users get 14B with reasoning"
      priority: 300
      rules:
        operator: "AND"
        conditions:
          - type: "authz"
            name: "admin"
      modelRefs:
        - model: "Qwen/Qwen2.5-14B-Instruct"
          use_reasoning: true
        - model: "Qwen/Qwen2.5-7B-Instruct"
          use_reasoning: false

    # ── Premium + complex → 14B ──
    - name: "premium_complex"
      description: "Premium users + complex queries get 14B"
      priority: 250
      rules:
        operator: "AND"
        conditions:
          - type: "authz"
            name: "premium_user"
          - type: "keyword"
            name: "complex_analysis"
      modelRefs:
        - model: "Qwen/Qwen2.5-14B-Instruct"
          use_reasoning: true

    # ── Premium + code → 14B ──
    - name: "premium_code"
      description: "Premium users + code requests get 14B"
      priority: 240
      rules:
        operator: "AND"
        conditions:
          - type: "authz"
            name: "premium_user"
          - type: "keyword"
            name: "code_request"
      modelRefs:
        - model: "Qwen/Qwen2.5-14B-Instruct"
          use_reasoning: false

    # ── Premium default → 7B ──
    - name: "premium_default"
      description: "Premium users simple queries get 7B"
      priority: 150
      rules:
        operator: "AND"
        conditions:
          - type: "authz"
            name: "premium_user"
      modelRefs:
        - model: "Qwen/Qwen2.5-7B-Instruct"
          use_reasoning: false

    # ── Free tier → 7B ──
    - name: "free_default"
      description: "Free users get 7B"
      priority: 100
      rules:
        operator: "AND"
        conditions:
          - type: "authz"
            name: "free_user"
      modelRefs:
        - model: "Qwen/Qwen2.5-7B-Instruct"
          use_reasoning: false

  # --- Semantic Cache ---
  semantic_cache:
    enabled: false

  # --- Router Configuration ---
  router:
    high_confidence_threshold: 0.99
    low_latency_threshold_ms: 2000
    default_confidence_threshold: 0.95
    default_max_latency_ms: 5000

  # --- Observability ---
  observability:
    metrics:
      enabled: true
    tracing:
      enabled: false

  # --- API Configuration ---
  api:
    batch_classification:
      max_batch_size: 100
      concurrency_threshold: 5
      max_concurrency: 8
      metrics:
        enabled: true
        detailed_goroutine_tracking: true
        high_resolution_timing: false
        sample_rate: 1.0
        duration_buckets:
          [0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10, 30]
        size_buckets: [1, 2, 5, 10, 20, 50, 100, 200]

resources:
  limits:
    cpu: 2000m
    memory: 8Gi
  requests:
    cpu: 500m
    memory: 2Gi
